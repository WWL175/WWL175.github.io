<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Git环境部署</title>
    <url>/2023/06/07/Git%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="GIT的发展简史"><a href="#GIT的发展简史" class="headerlink" title="GIT的发展简史"></a>GIT的发展简史</h2><p>在2002年以前，世界各地的志愿者把源代码文件通过diff的方式发给Linus，然后由Linus本人通过手工方式合并代码,不过，到了2002年，Linux系统已经发展了十年了，代码库之大让Linus很难继续通过手工方式管理了,于是Linus选择了一个商业的版本控制系统BitKeeper,另一方面,BitKeeper不是开源的. 显然与Linux 的开源精神不相符,所以linux 社区的很多人抱怨,不愿意使用。</p>
<p>Linus 本人 花了10天的时间Git 出来了,一个月之内，Linux系统的源码已经由Git管理了,Git 出来以后毕竟是一个人做的,开始并不好用(刚开始只能用勉强可以用来形容), 还是很多人抱怨,发展了很多年都没有干过其他软件。</p>
<p>直到 2008年，GitHub网站上线了，它为开源项目免费提供Git存储，无数开源项目开始迁移至GitHub,从此git 迎来了飞速发展,当下git 已经成为了最流行的版本控制工具。</p>
<h2 id="Git的工作流程"><a href="#Git的工作流程" class="headerlink" title="Git的工作流程"></a>Git的工作流程</h2><p>Git是分布式版本控制系统（Distributed Version Control System，简称 DVCS），分为两种类型的仓库：<br>本地仓库和远程仓库<br>工作流程如下：</p>
<h5 id="1．从远程仓库中克隆或拉取代码到本地仓库-clone-x2F-pull"><a href="#1．从远程仓库中克隆或拉取代码到本地仓库-clone-x2F-pull" class="headerlink" title="1．从远程仓库中克隆或拉取代码到本地仓库(clone&#x2F;pull)"></a>1．从远程仓库中克隆或拉取代码到本地仓库(clone&#x2F;pull)</h5><h5 id="2．从本地进行代码修改"><a href="#2．从本地进行代码修改" class="headerlink" title="2．从本地进行代码修改"></a>2．从本地进行代码修改</h5><h5 id="3．在提交前先将代码提交到暂存区"><a href="#3．在提交前先将代码提交到暂存区" class="headerlink" title="3．在提交前先将代码提交到暂存区"></a>3．在提交前先将代码提交到暂存区</h5><h5 id="4．提交到本地仓库。本地仓库中保存修改的各个历史版本"><a href="#4．提交到本地仓库。本地仓库中保存修改的各个历史版本" class="headerlink" title="4．提交到本地仓库。本地仓库中保存修改的各个历史版本"></a>4．提交到本地仓库。本地仓库中保存修改的各个历史版本</h5><h5 id="5．修改完成后，需要和团队成员共享代码时，将代码push到远程仓库"><a href="#5．修改完成后，需要和团队成员共享代码时，将代码push到远程仓库" class="headerlink" title="5．修改完成后，需要和团队成员共享代码时，将代码push到远程仓库"></a>5．修改完成后，需要和团队成员共享代码时，将代码push到远程仓库</h5><p><img src="/../image-git/1.jpg" alt="图 1">  </p>
<h2 id="GIT常用命令流程图"><a href="#GIT常用命令流程图" class="headerlink" title="GIT常用命令流程图:"></a>GIT常用命令流程图:</h2><p><img src="/../image-git/2.jpg" alt="图 3">  </p>
<h1 id="Git-的安装以及基础使用"><a href="#Git-的安装以及基础使用" class="headerlink" title="Git 的安装以及基础使用"></a>Git 的安装以及基础使用</h1><h2 id="一、下载"><a href="#一、下载" class="headerlink" title="一、下载"></a>一、下载</h2><p>git下载网址：<a href="https://git-scm.com/download">https://git-scm.com/download</a><br><img src="/../image-git/3.jpg" alt="图 4"><br>git客户端下载网址：<a href="https://tortoisegit.org/download/">https://tortoisegit.org/download/</a><br><img src="/../image-git/4.jpg" alt="图 5"><br>下载完成后<br><img src="/../image-git/5.jpg" alt="图 6"><br><img src="/../image-git/6.jpg" alt="图 7">  </p>
<h2 id="二、安装"><a href="#二、安装" class="headerlink" title="二、安装"></a>二、安装</h2><p>按照顺序直接下一步安装即可<br><img src="/../image-git/7.jpg" alt="图 8"><br><img src="/../image-git/8.jpg" alt="图 9">  </p>
<h4 id="更改语言"><a href="#更改语言" class="headerlink" title="更改语言"></a>更改语言</h4><p><img src="/../image-git/9.jpg" alt="图 10">  </p>
<h2 id="三、Git-的基本使用01-TortoiseGit-操作本地仓库"><a href="#三、Git-的基本使用01-TortoiseGit-操作本地仓库" class="headerlink" title="三、Git 的基本使用01-TortoiseGit 操作本地仓库"></a>三、Git 的基本使用01-TortoiseGit 操作本地仓库</h2><h3 id="1-初始化仓库初始化仓库"><a href="#1-初始化仓库初始化仓库" class="headerlink" title="1.初始化仓库初始化仓库"></a>1.初始化仓库初始化仓库</h3><p>新建一个文件夹,进入文件夹内部操作</p>
<h4 id="1-右键–-gt-在这里创建Git-版本库"><a href="#1-右键–-gt-在这里创建Git-版本库" class="headerlink" title="1)右键–&gt; 在这里创建Git 版本库"></a>1)右键–&gt; 在这里创建Git 版本库</h4><p><img src="/../image-git/10.jpg" alt="图 11">  </p>
<h3 id="2-添加文件"><a href="#2-添加文件" class="headerlink" title="2.添加文件"></a>2.添加文件</h3><h4 id="1-在仓库中新建一个文件"><a href="#1-在仓库中新建一个文件" class="headerlink" title="1)在仓库中新建一个文件"></a>1)在仓库中新建一个文件</h4><h4 id="2-选中新建的文件–-gt-右键–-gt-TortoiseGit–-gt-添加"><a href="#2-选中新建的文件–-gt-右键–-gt-TortoiseGit–-gt-添加" class="headerlink" title="2)选中新建的文件–&gt;右键–&gt; TortoiseGit–&gt; 添加"></a>2)选中新建的文件–&gt;右键–&gt; TortoiseGit–&gt; 添加</h4><h4 id="3-此时我们看到文件夹上多了一个-“加号”"><a href="#3-此时我们看到文件夹上多了一个-“加号”" class="headerlink" title="3)此时我们看到文件夹上多了一个 “加号”"></a>3)此时我们看到文件夹上多了一个 “加号”</h4><p><img src="/../image-git/11.jpg" alt="图 12">  </p>
<h3 id="3-提交文件至本地仓库"><a href="#3-提交文件至本地仓库" class="headerlink" title="3.提交文件至本地仓库"></a>3.提交文件至本地仓库</h3><h4 id="1-选中文件"><a href="#1-选中文件" class="headerlink" title="1)选中文件"></a>1)选中文件</h4><h4 id="2-右键–git提交"><a href="#2-右键–git提交" class="headerlink" title="2) 右键–git提交"></a>2) 右键–git提交</h4><p><img src="/../image-git/12.jpg" alt="图 13">  </p>
<h3 id="4-修改文件-与再次提交文件"><a href="#4-修改文件-与再次提交文件" class="headerlink" title="4.修改文件,与再次提交文件"></a>4.修改文件,与再次提交文件</h3><p><img src="/../image-git/13.jpg" alt="图 15">  </p>
<h3 id="5-查看提交历史记录"><a href="#5-查看提交历史记录" class="headerlink" title="5.查看提交历史记录"></a>5.查看提交历史记录</h3><p>选中文件<br>右键–&gt; TortoiseGit–&gt; 显示日志<br>（此时我们可以看到所有的历史提交记录）<br><img src="/../image-git/14.jpg" alt="图 16">  </p>
<h3 id="6-回退至历史版本"><a href="#6-回退至历史版本" class="headerlink" title="6.回退至历史版本"></a>6.回退至历史版本</h3><p>右键–&gt; TortoiseGit–&gt; 显示日志<br>选中某个版本–&gt; 进行如下操作<br><img src="/../image-git/15.jpg" alt="图 17">  </p>
<h3 id="7-本地删除与恢复"><a href="#7-本地删除与恢复" class="headerlink" title="7.本地删除与恢复"></a>7.本地删除与恢复</h3><p>直接选中文件删除的话,其实只是删除了本地工作区的文件,并没有删除 仓库中的文件<br>   此时时可以回退的, 比如我们进行如下操作：</p>
<h4 id="1-文件删除"><a href="#1-文件删除" class="headerlink" title="1)文件删除"></a>1)文件删除</h4><h4 id="2-右键–-gt-TortoiseGit–-gt-还原"><a href="#2-右键–-gt-TortoiseGit–-gt-还原" class="headerlink" title="2)右键–&gt; TortoiseGit–&gt; 还原"></a>2)右键–&gt; TortoiseGit–&gt; 还原</h4><p>   此时我们发现文件又被恢复了<br><img src="/../image-git/16.jpg" alt="图 18"><br><img src="/../image-git/17.jpg" alt="图 19">  </p>
<h3 id="8-从版本库删除-但是不删除本地"><a href="#8-从版本库删除-但是不删除本地" class="headerlink" title="8.从版本库删除,但是不删除本地"></a>8.从版本库删除,但是不删除本地</h3><p><img src="/../image-git/18.jpg" alt="图 20">  </p>
<h3 id="9-创建分支"><a href="#9-创建分支" class="headerlink" title="9.创建分支"></a>9.创建分支</h3><p><img src="/../image-git/1.jpg" alt="图 21">  </p>
<h3 id="10-查看分支"><a href="#10-查看分支" class="headerlink" title="10.查看分支"></a>10.查看分支</h3><p><img src="/../image-git/19.jpg" alt="图 22">  </p>
<h3 id="11-切换分支"><a href="#11-切换分支" class="headerlink" title="11.切换分支"></a>11.切换分支</h3><p>右键–&gt; 检出<br><img src="/../image-git/20.jpg" alt="图 23">  </p>
<h3 id="12-合并"><a href="#12-合并" class="headerlink" title="12.合并"></a>12.合并</h3><p>我们将代码切换到分支1,然后写属于需求1 的代码并提交<br>当我们把需求1 开发完毕如何把需求1 的代码合并到主分支呢?</p>
<h4 id="–-gt-1-切换到-主版本"><a href="#–-gt-1-切换到-主版本" class="headerlink" title="–&gt;1 切换到 主版本"></a>–&gt;1 切换到 主版本</h4><h4 id="–-gt-2-右键-合并即可将需求1-写的代码合并至主分支"><a href="#–-gt-2-右键-合并即可将需求1-写的代码合并至主分支" class="headerlink" title="–&gt;2 右键 合并即可将需求1 写的代码合并至主分支"></a>–&gt;2 右键 合并即可将需求1 写的代码合并至主分支</h4><h4 id="—–此时我们看到代码自动合并到了master分支"><a href="#—–此时我们看到代码自动合并到了master分支" class="headerlink" title="—–此时我们看到代码自动合并到了master分支"></a>—–此时我们看到代码自动合并到了master分支</h4><p><img src="/../image-git/21.jpg" alt="图 24">  </p>
<h3 id="13-删除分支"><a href="#13-删除分支" class="headerlink" title="13.删除分支"></a>13.删除分支</h3><p><img src="/../image-git/22.jpg" alt="图 25">  </p>
<h3 id="14-冲突的处理"><a href="#14-冲突的处理" class="headerlink" title="14.冲突的处理"></a>14.冲突的处理</h3><p><img src="/../image-git/23.jpg" alt="图 26">  </p>
<h3 id="15-标签的创建-tag"><a href="#15-标签的创建-tag" class="headerlink" title="15.标签的创建(tag)"></a>15.标签的创建(tag)</h3><p>标签的创建和分支的创建操作几乎一样<br><img src="/../image-git/24.jpg" alt="图 27">  </p>
<h3 id="16-标签的切换与删除"><a href="#16-标签的切换与删除" class="headerlink" title="16.标签的切换与删除"></a>16.标签的切换与删除</h3><p><img src="/../image-git/25.jpg" alt="图 28"><br><img src="/../image-git/26.jpg" alt="图 29">  </p>
<h3 id="17-本地相对路径-多个文件夹之间共享代码"><a href="#17-本地相对路径-多个文件夹之间共享代码" class="headerlink" title="17.本地相对路径,多个文件夹之间共享代码"></a>17.本地相对路径,多个文件夹之间共享代码</h3><p><img src="/../image-git/27.jpg" alt="图 30">  </p>
<h3 id="18-开启局域网共享代码"><a href="#18-开启局域网共享代码" class="headerlink" title="18.开启局域网共享代码"></a>18.开启局域网共享代码</h3><p><img src="/../image-git/28.jpg" alt="图 31"><br>局域网这种共享是没有安全控制的,都可以访问,如果想要搭建一个可以控制权限的服务器需要借助第三方软件</p>
<h2 id="四、常用远程仓库托管服务"><a href="#四、常用远程仓库托管服务" class="headerlink" title="四、常用远程仓库托管服务"></a>四、常用远程仓库托管服务</h2><p>除了自己搭建服务器,其实我们可以使用一些免费的远程仓库，例如：<a href="http://www.gitee.com/">www.gitee.com</a></p>
<h3 id="1-码云账号注册"><a href="#1-码云账号注册" class="headerlink" title="1.码云账号注册"></a>1.码云账号注册</h3><p><img src="/../image-git/29.jpg" alt="图 32">  </p>
<h3 id="2-创建远程仓库"><a href="#2-创建远程仓库" class="headerlink" title="2.创建远程仓库"></a>2.创建远程仓库</h3><p><img src="/../image-git/30.jpg" alt="图 33">  </p>
<h3 id="3-查看仓库地址"><a href="#3-查看仓库地址" class="headerlink" title="3.查看仓库地址"></a>3.查看仓库地址</h3><p><img src="/../image-git/31.jpg" alt="图 34">  </p>
<h3 id="4-把本地代码推送到远端"><a href="#4-把本地代码推送到远端" class="headerlink" title="4.把本地代码推送到远端"></a>4.把本地代码推送到远端</h3><p><img src="/../image-git/32.jpg" alt="图 35"><br><img src="/../image-git/33.jpg" alt="图 36"><br><img src="/../image-git/34.jpg" alt="图 37">  </p>
<h3 id="5-从远程仓库克隆代码"><a href="#5-从远程仓库克隆代码" class="headerlink" title="5.从远程仓库克隆代码"></a>5.从远程仓库克隆代码</h3><p>我们同样可以从库下载代码,新建一个文件夹 repo2 ,进入然后进行如下操作。<br><img src="/../image-git/35.jpg" alt="图 38"><br><img src="/../image-git/36.jpg" alt="图 39"><br>此时我们发现我们的代码已经被下载下来了</p>
<h2 id="五、ssh-连接概述"><a href="#五、ssh-连接概述" class="headerlink" title="五、ssh 连接概述"></a>五、ssh 连接概述</h2><p>实际上git 不仅仅支持用户名密码方式的配置,可以有另外一种相对更加安全的配置即ssh 方式配置</p>
<h3 id="1-ssh-密钥的生成"><a href="#1-ssh-密钥的生成" class="headerlink" title="1.ssh 密钥的生成"></a>1.ssh 密钥的生成</h3><h4 id="生成公钥私钥"><a href="#生成公钥私钥" class="headerlink" title="生成公钥私钥"></a>生成公钥私钥</h4><p>ssh-keygen -t rsa<br>一直回车即可<br>会默认用户目录 .ssh 目录生成一个默认的id_rsa文件 和id_rsa.pub<br><img src="/../image-git/37.jpg" alt="图 40">  </p>
<h3 id="2-ssh-密钥配置"><a href="#2-ssh-密钥配置" class="headerlink" title="2.ssh 密钥配置"></a>2.ssh 密钥配置</h3><p><img src="/../image-git/38.jpg" alt="图 41"><br><img src="/../image-git/39.jpg" alt="图 42">  </p>
<h3 id="3-ssh-方式克隆-x2F-提交代码"><a href="#3-ssh-方式克隆-x2F-提交代码" class="headerlink" title="3.ssh 方式克隆&#x2F;提交代码:"></a>3.ssh 方式克隆&#x2F;提交代码:</h3><p><img src="/../image-git/40.jpg" alt="图 43">  </p>
<h1 id="问题总结"><a href="#问题总结" class="headerlink" title="问题总结"></a>问题总结</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">同时，我通过对GIT的安装、启动、运行、解决问题的一系列完成，对此了解越来越深：</span><br><span class="line"></span><br><span class="line">上述我们的操作 使用的 是客户端TortoiseGit 操作的git ,实际上底层依旧是使用的命令行帮我们执行, 在早期 git 并没有窗口化工具,开发人员只能使用命令行模式</span><br><span class="line"></span><br><span class="line">实际上,如果你掌握并熟练使用了命令行模式操作git 的话,你会发现某些操作命令行比窗口化操作要简单</span><br><span class="line">所有你在工作中会发现高深的技术人员可能会喜欢命令行模式提交git，当下git 已经成为了最流行的版本控制工具。</span><br><span class="line"></span><br><span class="line">最后，通过这次实践，积极向同学询问其中的疑问，在同学的帮助下解决困难，完成作业，对与其中的不足也是我后续将继续学习的地方。</span><br></pre></td></tr></table></figure>

]]></content>
  </entry>
  <entry>
    <title>Kafka zookeeper 环境部署</title>
    <url>/2023/06/20/Kafka%20zookeeper%20/</url>
    <content><![CDATA[<h1 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h1><h2 id="一、初始zookeeper"><a href="#一、初始zookeeper" class="headerlink" title="一、初始zookeeper"></a>一、初始zookeeper</h2><p>ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件。<br>Zookeeper 是 Apache Hadoop 项目下的一个子项目，是一个树形目录服务。Zookeeper 翻译过来就是 动物园管理员，他是用来管 Hadoop（大象）、Hive(蜜蜂)、Pig(小 猪)的管理员，简称zk。</p>
<h3 id="Zookeeper-的主要功能："><a href="#Zookeeper-的主要功能：" class="headerlink" title="Zookeeper 的主要功能："></a>Zookeeper 的主要功能：</h3><p>配置管理<br>分布式锁<br>集群管理</p>
<h3 id="Zookeeper的工作原理："><a href="#Zookeeper的工作原理：" class="headerlink" title="Zookeeper的工作原理："></a>Zookeeper的工作原理：</h3><p>ZooKeeper是以Fast Paxos算法为基础的，Paxos 算法存在活锁的问题，即当有多个proposer交错提交时，有可能互相排斥导致没有一个proposer能提交成功，而Fast Paxos做了一些优化，通过选举产生一个leader (领导者)，只有leader才能提交proposer，具体算法可见Fast Paxos。因此，要想弄懂ZooKeeper首先得对Fast Paxos有所了解。</p>
<h3 id="ZooKeeper的基本运转流程："><a href="#ZooKeeper的基本运转流程：" class="headerlink" title="ZooKeeper的基本运转流程："></a>ZooKeeper的基本运转流程：</h3><p>1、选举Leader。<br>2、同步数据。<br>3、选举Leader过程中算法有很多，但要达到的选举标准是一致的。<br>4、Leader要具有最高的执行ID，类似root权限。<br>5、集群中大多数的机器得到响应并接受选出的Leader。</p>
<p><img src="/../imagek/1.png"></p>
<h1 id="二、Zookeeper的安装与配置"><a href="#二、Zookeeper的安装与配置" class="headerlink" title="二、Zookeeper的安装与配置"></a>二、Zookeeper的安装与配置</h1><h2 id="第一步-准备工作"><a href="#第一步-准备工作" class="headerlink" title="第一步 准备工作"></a>第一步 准备工作</h2><p>安装前需要安装好jdk<br>检测集群时间是否同步<br>检测防火墙是否关闭<br>检测主机 ip映射有没有配置</p>
<p><img src="/../imagek/2.png"></p>
<p><img src="/../imagek/3.png"></p>
<h2 id="第二步-解压"><a href="#第二步-解压" class="headerlink" title="第二步 解压"></a>第二步 解压</h2><p>在node1主机上，解压zookeeper的压缩包到&#x2F;export&#x2F;server路径下去，然后准备进行安装<br>cd &#x2F;export&#x2F;software<br>tar -zxvf zookeeper.tar.gz -C &#x2F;export&#x2F;server&#x2F;</p>
<p><img src="/../imagek/4.png"></p>
<p>cd &#x2F;export&#x2F;server&#x2F;<br>ln -s zookeeper&#x2F; zookeeper</p>
<p><img src="/../imagek/5.png"></p>
<h2 id="第三步-环境变量"><a href="#第三步-环境变量" class="headerlink" title="第三步 环境变量"></a>第三步 环境变量</h2><p>vi &#x2F;etc&#x2F;profile<br>export ZOOKEEPER_HOME&#x3D;&#x2F;export&#x2F;server&#x2F;zookeeper<br>export PATH&#x3D;$PATH:$ZOOKEEPER_HOME&#x2F;bin<br>source &#x2F;etc&#x2F;profile</p>
<p><img src="/../imagek/6.png"></p>
<p><img src="/../imagek/7.png"></p>
<h2 id="第四步-配置文件"><a href="#第四步-配置文件" class="headerlink" title="第四步 配置文件"></a>第四步 配置文件</h2><p>修改Zookeeper配置文件<br>cd &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;conf&#x2F;<br>cp zoo_sample.cfg zoo.cfg：</p>
<p><img src="/../imagek/8.png"></p>
<p>mkdir -p &#x2F;export&#x2F;data&#x2F;zookeeper&#x2F;zkdatas&#x2F;<br>vim zoo.cfg</p>
<p><img src="/../imagek/9.png"></p>
<h2 id="第五步-添加myid配置"><a href="#第五步-添加myid配置" class="headerlink" title="第五步 添加myid配置"></a>第五步 添加myid配置</h2><p>echo 1 &gt; &#x2F;export&#x2F;data&#x2F;zkdatas&#x2F;myid</p>
<p><img src="/../imagek/10.png"></p>
<h2 id="第六步-安装包分发并修改myid的值"><a href="#第六步-安装包分发并修改myid的值" class="headerlink" title="第六步 安装包分发并修改myid的值"></a>第六步 安装包分发并修改myid的值</h2><h3 id="（1）在node1主机上，将安装包分发到其他机器"><a href="#（1）在node1主机上，将安装包分发到其他机器" class="headerlink" title="（1）在node1主机上，将安装包分发到其他机器"></a>（1）在node1主机上，将安装包分发到其他机器</h3><p>第一台机器上面执行以下两个命令<br>cd &#x2F;export&#x2F;server&#x2F;<br>scp -r &#x2F;export&#x2F;server&#x2F;zookeeper-3.4.6&#x2F; root@node2:&#x2F;export&#x2F;server&#x2F;</p>
<p><img src="/../imagek/11.png"></p>
<p>scp -r &#x2F;export&#x2F;server&#x2F;zookeeper-3.4.6&#x2F; root@node2:&#x2F;export&#x2F;server&#x2F;</p>
<p><img src="/../imagek/12.png"></p>
<h3 id="（2）第二台机器上建立软连接-并修改myid的值为2"><a href="#（2）第二台机器上建立软连接-并修改myid的值为2" class="headerlink" title="（2）第二台机器上建立软连接, 并修改myid的值为2"></a>（2）第二台机器上建立软连接, 并修改myid的值为2</h3><p>cd &#x2F;export&#x2F;server&#x2F;<br>ln -s zookeeper-3.4.6&#x2F; zookeeper<br>echo 2 &gt; &#x2F;export&#x2F;data&#x2F;zookeeper&#x2F;zkdatas&#x2F;yid</p>
<p><img src="/../imagek/13.png"></p>
<h3 id="（3）第三台机器上建立软连接-并修改myid的值为3"><a href="#（3）第三台机器上建立软连接-并修改myid的值为3" class="headerlink" title="（3）第三台机器上建立软连接, 并修改myid的值为3"></a>（3）第三台机器上建立软连接, 并修改myid的值为3</h3><p>cd &#x2F;export&#x2F;server&#x2F;<br>ln -s zookeeper-3.4.6&#x2F; zookeeper</p>
<p><img src="/../imagek/14.png"></p>
<h1 id="三、三台机器启动zookeeper服务测试"><a href="#三、三台机器启动zookeeper服务测试" class="headerlink" title="三、三台机器启动zookeeper服务测试"></a>三、三台机器启动zookeeper服务测试</h1><h2 id="第一步"><a href="#第一步" class="headerlink" title="第一步"></a>第一步</h2><p>三台机器分别启动zookeeper服务<br>这个命令三台机器都要执行<br>&#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;bin&#x2F;zkServer.sh start</p>
<p><img src="/../imagek/15.png"></p>
<p><img src="/../imagek/16.png"></p>
<p>三台主机分别查看启动状态<br>&#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;bin&#x2F;zkServer.sh status</p>
<p><img src="/../imagek/17.png"></p>
<p><img src="/../imagek/18.png"></p>
<h2 id="第二步"><a href="#第二步" class="headerlink" title="第二步"></a>第二步</h2><p>启动（每台机器）<br>zkServer.sh start 或者编写一个脚本来批量启动所有机器：</p>
<p><img src="/../imagek/19.png"></p>
<p><img src="/../imagek/20.png"></p>
<p><img src="/../imagek/21.png"></p>
<h3 id="方法1："><a href="#方法1：" class="headerlink" title="方法1："></a>方法1：</h3><p>for host in “node1 node2 node3”<br>do<br>   ssh $host “source&#x2F;etc&#x2F;profile;&#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;bin&#x2F;zkServer.sh start”<br>done<br>方法2：<br>1.创建&#x2F;export&#x2F;server&#x2F;start&#x2F;zk_start目录<br>mkdir &#x2F;export&#x2F;shell<br>2.编辑创建zk.sh<br>vim zkall.sh<br>3.写shell脚本</p>
<p><img src="/../imagek/22.png"></p>
<p>4.配置zk脚本环境变量<br>#ZOOKEEPER_SHELL_HOME<br>export ZKS_HOME&#x3D;&#x2F;export&#x2F;shell&#x2F;<br>export PATH&#x3D;$PATH:$ZKS_HOME</p>
<p>5.zookeeper的环境变量<br>export ZK_HOME&#x3D;&#x2F;export&#x2F;server&#x2F;zookeeper<br>export PATH&#x3D;${ZK_HOME}&#x2F;bin:$PATH</p>
<p>6.让环境变量生效<br>source &#x2F;etc&#x2F;profile</p>
<p>7.启动测试<br>chmod 777 &#x2F;export&#x2F;shell&#x2F;zkall.sh<br>zkall.sh start</p>
<p><img src="/../imagek/23.png"></p>
<p>启动成功，测试结束！</p>
<h1 id="四、问题与总结"><a href="#四、问题与总结" class="headerlink" title="四、问题与总结"></a>四、问题与总结</h1><p>在本节zookeeper的的学习中我们了解和解决了zookeeper的的核心问题——Zookeeper 集群<br>在ZooKeeper集群服中务中有三个角色：<br>Leader 领导者 ： 处理事务请求； 集群内部各服务器的调度者<br>Follower 跟随者 ：处理客户端非事务请求，转发事务请求给Leader服务器； 参与Leader选举投票<br>Observer 观察者：处理客户端非事务请求，转发事务请求给Leader服务器</p>
<p><img src="/../imagek/24.png"></p>
<h3 id="同时，"><a href="#同时，" class="headerlink" title="同时，"></a>同时，</h3><p>我们通过对zookeeper的研究、安装、启动、运行、解决问题的一系列完成，对此了解越来越深：<br>ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。我们也通过思考和查询资料发现它是一个为分布式应用提供一致性服务的软件，探索归纳出zookeeper的功能：配置维护、域名服务、分布式同步、组服务等。通过这些功能，ZooKeeper 为分布式应用程序提供了一致性、可靠性和高效性的支持，简化了分布式系统的开发和管理。以此，我们可以利用zookeeper广泛应用于分布式数据库、分布式缓存、分布式锁、分布式协调和配置管理等场景。</p>
<h3 id="综上，"><a href="#综上，" class="headerlink" title="综上，"></a>综上，</h3><p>我们也意识到ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。当客户端接收到事件信息，可以调用相应的行为来处理数据。Zookeeper的Wiki页面展示了如何使用Zookeeper来处理事件通知，队列，优先队列，锁，共享锁，可撤销的共享锁，两阶段提交。<br>最后，会看在这次实践，我们相互配合，历经自我学习，组合探究，积极向同学询问，查阅资料，获取了满意的结果，我们也十分骄傲，望继承优良传统，下次再接再厉！</p>
<p>　</p>
]]></content>
  </entry>
  <entry>
    <title>7.Spark(Pyspark基础编译环境）</title>
    <url>/2023/06/09/Spark(Pyspark%E5%9F%BA%E7%A1%80%E7%BC%96%E8%AF%91%E7%8E%AF%E5%A2%83%EF%BC%89/</url>
    <content><![CDATA[<h1 id="7-1本地Pyspark环境配置"><a href="#7-1本地Pyspark环境配置" class="headerlink" title="7.1本地Pyspark环境配置"></a>7.1本地Pyspark环境配置</h1><ul>
<li><p>首先需要<code>本地安装 Anaconda</code>（下载安装过程在这不再讲解），利用Anaconda 创建基于Python3.8 的Pyspark 的虚拟环境。以下为安装命令：（命令在 Anaconda Powershell 中执行）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#创建虚拟环境 pyspark, 基于 Python 3.8</span><br><span class="line">conda create -n pyspark python=3.8</span><br><span class="line"></span><br><span class="line">#切换到虚拟环境内</span><br><span class="line">conda activate pyspark</span><br><span class="line"></span><br><span class="line">#在安装包的过程中如果速度过慢可通过指令手动添加镜像或者将国内源配置在 Anaconda 中方便下载，以下以本机为例添加镜像：</span><br><span class="line">conda config --set show_channel_urls yes</span><br></pre></td></tr></table></figure>
</li>
<li><p>然后用记事本打开:C:\Users\用户名\<code>.condarc文件</code>, 将如下内容替换进文件内,保存即可:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">channels:</span><br><span class="line"> - defaults</span><br><span class="line">show_channel_urls: true</span><br><span class="line">default_channels:</span><br><span class="line"> - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main</span><br><span class="line"> - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r</span><br><span class="line"> - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2</span><br><span class="line">custom_channels:</span><br><span class="line"> conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line"> msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line"> bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line"> menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line"> pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line"> simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br></pre></td></tr></table></figure></li>
</ul>
<p><img src="/../images/1.png" alt="1.png"></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">在虚拟环境内安装包</span></span><br><span class="line">pip install pyhive pyspark jieba -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure>

<ul>
<li>安装完成后结果见下图：</li>
</ul>
<p><img src="/../images/2.png" alt="2.png"></p>
<ul>
<li><p>在本机中还需要<code>安装Hadoop DDL</code>，因为PySpark在运行计算服务过程中会使用到Hadoop中的Mapreduce服务，所以需要在本机中添加补丁：</p>
</li>
<li><p>将课程资料中提供的: <code>hadoop-3.3.0 文件</code>, 解压复制到本机,例如：</p>
</li>
</ul>
<p><img src="/../images/3.png" alt="3.png"></p>
<ul>
<li>并把bin目录下的hadoop.dll复制到<code>C:\Windows\System32\</code>路径下:</li>
</ul>
<p><img src="/../images/4.png" alt="4.png"></p>
<ul>
<li>在本机的环境变量的系统变量设置中<code>配置HADOOP_HOME环境变量</code>指向 hadoop-3.3.0文件夹的路径：</li>
</ul>
<p><img src="/../images/5.png" alt="5.png"></p>
<h1 id="7-2在PyCharm中配置本地Python解释器"><a href="#7-2在PyCharm中配置本地Python解释器" class="headerlink" title="7.2在PyCharm中配置本地Python解释器"></a>7.2在PyCharm中配置本地Python解释器</h1><ul>
<li>首先需要下载<a href="https://www.jetbrains.com/pycharm/">专业版Pycharm</a>，在PyCharm中的设置中配置Python解析器。</li>
</ul>
<p><img src="/../images/6.png" alt="6.png"></p>
<ul>
<li>配置Linux环境中的Pyspark解释器，这样才能通过本机的Python Spark脚本运行对Linux进行远程运算：</li>
<li>设置远程SSH python Pyspark环境</li>
</ul>
<p><img src="/../images/7.png" alt="7.png"></p>
<ul>
<li>设置虚拟机中的python环境路径：</li>
<li>可以先查看Linux中的pyspark中的python路径，方便添加到pycharm的解释器中，以本机的路径为例：  <code>/export/server/anaconda3/envs/pyspark/bin/python3</code></li>
</ul>
<p><img src="/../images/8.png" alt="8.png"></p>
<p><img src="/../images/9.png" alt="9.png"></p>
<ul>
<li><code>将Anaconda中Pyspark路径添加至本机的环境变量</code>，否则在接下来的Pyspark Python代码执行时无法调用Pyspark：</li>
</ul>
<p><img src="/../images/10.png" alt="10.png"></p>
<h1 id="7-3导入构建Pyspark-python脚本文件"><a href="#7-3导入构建Pyspark-python脚本文件" class="headerlink" title="7.3导入构建Pyspark python脚本文件"></a>7.3导入构建Pyspark python脚本文件</h1><ul>
<li>新建名为Pyspark的项目，<code>解释器选择本机的Pyspark python环境</code>，新建HelloWorld.py文件，导入以下代码：</li>
</ul>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># coding:utf8</span></span><br><span class="line"><span class="attr">from</span> <span class="string">pyspark import SparkConf, SparkContext</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># import os</span></span><br><span class="line"><span class="comment"># os.environ[&#x27;PYSPARK_PYTHON&#x27;]=&#x27;D:\\Anaconda\\envs\\pyspark\\python.exe&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">if</span> <span class="string">__name__ == &#x27;__main__&#x27;:</span></span><br><span class="line">    <span class="attr">conf</span> = <span class="string">SparkConf().setAppName(&quot;WordCountHelloWorld&quot;).setMaster(&quot;local[*]&quot;)</span></span><br><span class="line"><span class="comment">    # 通过SparkConf对象构建SparkContext对象</span></span><br><span class="line">    <span class="attr">sc</span> = <span class="string">SparkContext(conf=conf)</span></span><br><span class="line"><span class="comment">    # 需求 : wordcount单词计数, 读取HDFS上的words.txt文件, 对其内部的单词统计出现 的数量</span></span><br><span class="line"><span class="comment">    # 读取文件</span></span><br><span class="line"><span class="comment">    # file_rdd = sc.textFile(&quot;hdfs://node1:8020/input/words.txt&quot;) #hdfs路径</span></span><br><span class="line">    <span class="attr">file_rdd</span> = <span class="string">sc.textFile(&quot;file:///tmp/pycharm_project_360/data/input/words.txt&quot;)</span></span><br><span class="line"><span class="comment">    # file_rdd = sc.textFile(&quot;./data/input/words.txt&quot;)</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    # 将单词进行切割, 得到一个存储全部单词的集合对象</span></span><br><span class="line">    <span class="attr">words_rdd</span> = <span class="string">file_rdd.flatMap(lambda line: line.split(&quot; &quot;))</span></span><br><span class="line"><span class="comment">    # 将单词转换为元组对象, key是单词, value是数字1</span></span><br><span class="line">    <span class="attr">words_with_one_rdd</span> = <span class="string">words_rdd.map(lambda x: (x, 1))</span></span><br><span class="line"><span class="comment">    # 将元组的value 按照key来分组, 对所有的value执行聚合操作(相加)</span></span><br><span class="line">    <span class="attr">result_rdd</span> = <span class="string">words_with_one_rdd.reduceByKey(lambda a, b: a + b)</span></span><br><span class="line"><span class="comment">    # 通过collect方法收集RDD的数据打印输出结果</span></span><br><span class="line">    <span class="attr">print(result_rdd.collect())</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>在本地新建文件word.txt加入一些文本，并添加本地路径至代码中：</li>
</ul>
<p><img src="/../images/11.png" alt="11.png"></p>
<ul>
<li><strong>特别注意的是在本地执行wordcount计数时，pyspark的本机环境需提前配置或者可以在代码中手动引用Pyspark Python环境变量，例如：</strong></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">os.environ[&#x27;PYSPARK_PYTHON&#x27;]=&#x27;D:\\Anaconda\\envs\\pyspark\\python.exe&#x27;</span><br></pre></td></tr></table></figure>
<h1 id="7-4WordCount代码实例"><a href="#7-4WordCount代码实例" class="headerlink" title="7.4	WordCount代码实例"></a>7.4	WordCount代码实例</h1><ul>
<li>在本地RDD读取words.txt进行WordCount计数：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#在读取文件代码下只开启：</span><br><span class="line">file_rdd = sc.textFile(&quot;./data/input/words.txt&quot;)</span><br></pre></td></tr></table></figure></li>
<li>选择本地的Pyspark Python解释器并运行：</li>
</ul>
<p><img src="/../images/12.png" alt="12.png"></p>
<ul>
<li>在本地RDD读取Linux中HDFS上的words.txt进行WordCount计数:</li>
<li>首先需在HDFS上<code>创建并放置words.txt文件</code>:</li>
</ul>
<p><img src="/../images/13.png" alt="13.png"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> #在读取文件代码中设置HDFS上的路径：</span><br><span class="line">file_rdd = sc.textFile(&quot;hdfs://node1:8020/input/words.txt&quot;)</span><br></pre></td></tr></table></figure>
<ul>
<li>选择本地的Pyspark Python解释器并运行：</li>
</ul>
<p><img src="/../images/14.png" alt="14.png"></p>
<ul>
<li>在Linux中RDD读取Linux中的words.txt进行WordCount计数：</li>
<li>首先<code>在远程服务器端创建对应的Pycharm项目路径及文件</code>，例如：</li>
</ul>
<p><img src="/../images/15.png" alt="15.png"></p>
<blockquote>
<p><strong>Pycharm中也有功能对远程服务器进行同步文件</strong></p>
</blockquote>
<ul>
<li>在远程端激活Pyspark环境，将HelloWord.py文件中读取文件下的代码<code>只开启读取远程服务器下的路径</code>：</li>
</ul>
<p><img src="/../images/16.png" alt="16.png"></p>
<ul>
<li>在本地切换为远程Pyspark Python解释器，并运行：</li>
</ul>
<p><img src="/../images/17.png" alt="17.png"></p>
<ul>
<li>将代码提交至YARN集群进行测试：<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/spark-submit --master yarn --name wordcount /HelloWorld.py</span><br></pre></td></tr></table></figure>
<img src="/../images/18.png" alt="18.png"></li>
</ul>
<p><img src="/../images/19.png" alt="19.png"></p>
<p><strong>在运行Pyspark过程中需要注意的问题：</strong></p>
<blockquote>
<ol>
<li>需要对原来的pyspark进行卸载<br>pip uninstall pyspark</li>
<li>将本机及远程服务器中的Pyspark安装为3.2.0版本;<br>pip install pyspark&#x3D;&#x3D;3.2.0 -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></li>
</ol>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>SparkLocal</title>
    <url>/2023/06/08/Spark%E8%AF%BE%E7%A8%8B%E5%85%A8%E6%B5%81%E7%A8%8B%E9%85%8D%E7%BD%AEsparklocal/</url>
    <content><![CDATA[<h1 id="Spark-local-部署"><a href="#Spark-local-部署" class="headerlink" title="Spark(local)部署"></a>Spark(local)部署</h1><h1 id="一、回顾认识Spark-Local"><a href="#一、回顾认识Spark-Local" class="headerlink" title="一、回顾认识Spark-Local"></a>一、回顾认识Spark-Local</h1><p>Spark 是由一个强大而活跃的开源社区开发和维护的，是一个用来实现快速，通用的集群计算平台，适用于各种各样原先需要多种不同的分布式平台的场景，包括批处理，迭代算法，交互式查询，流处理。通过在一个统一的框架下支持这些不同的计算，spark使我们可以简单而低耗地把各种处理流程整合在一起。具备 SQL、统计、预测建模（机器学习）等方面的经验，以及一定的python，matlab，R语言能力的数据科学家对数据进行分析，以回答问题或发现一些潜在规律。</p>
<p>Spark的架构角色 - 理解<br>YARN主要有4类角色,从2个层面去看:</p>
<h3 id="资源管理层面"><a href="#资源管理层面" class="headerlink" title="资源管理层面"></a>资源管理层面</h3><p>集群资源管理者(Master):ResourceManager<br>单机资源管理者(Worker):NodeManager </p>
<h3 id="任务计算层面"><a href="#任务计算层面" class="headerlink" title="任务计算层面"></a>任务计算层面</h3><p>单任务管理者(Master):ApplicationMaster<br>单任务执行者(Worker):Task(容器内计算框架的工作角色)</p>
<p><img src="/../image-local/1.png"></p>
<p><img src="/../image-local/2.png"></p>
<h3 id="Spark提供多种运行模式"><a href="#Spark提供多种运行模式" class="headerlink" title="Spark提供多种运行模式"></a>Spark提供多种运行模式</h3><p>本地模式(单机)<br>Standalone模式(集群)<br>Hadoop YARN模式(集群)<br>Kubernetes模式(容器集群)</p>
<p>综上我们可以把Spark任务的运行，运行方式可分为三大类。即本地运行，集群运行和云模式，在此节我们聚焦到Spark的本地运行模式。</p>
<h1 id="二、Spark-Local基本原理"><a href="#二、Spark-Local基本原理" class="headerlink" title="二、Spark-Local基本原理"></a>二、Spark-Local基本原理</h1><p>Spark在本地运行模式一般在开发测试时使用，该模式通过在本地的一个JVM进程中同时运行driver和1个executor进程，实现Spark任务的本地运行。其本质:启动一个JVM Process进程(一个进程里面有多个线程),执行任务Task<br>	Local模式可以限制模拟Spark集群环境的线程数量, 即Local[N] 或 Local[<em>]<br>	其中N代表可以使用N个线程,每个线程拥有一个cpu core。如果不指定N, 则默认是1个线程(该线程有1个core)。 通常Cpu有几个Core,就指定几个线程,最大化利用计算能力。<br>	如果是local[</em>],则代表 Run Spark locally with as many worker threads as logical cores on your machine.按照Cpu最多的Cores设置线程数。</p>
<p><img src="/../image-local/3.png"></p>
<p>在Local运行模式中，Driver和Executor运行在同一个节点的同一个JVM中。在Local模式下，只启动了一个Executor。根据不同的Master URL，Executor中可以启动不同的工作线程，用于执行Task。Local模式Driver和Executor关系</p>
<p><img src="/../image-local/4.png"></p>
<h3 id="Local-下的角色分布"><a href="#Local-下的角色分布" class="headerlink" title="Local 下的角色分布:"></a>Local 下的角色分布:</h3><p>	资源管理:<br>Master:Local进程本身<br>Worker:Local进程本身<br>	任务执行:<br>Driver:Local进程本身<br>Executor:不存在,没有独立的Executor角色, 由Local进程(也就是Driver)内的线程提供计算能力<br>PS: Driver也算一种特殊的Executor, 只不过多数时候, 我们将Executor当做纯Worker对待, 这样和Driver好区分(一类是管理 一类是工人) </p>
<h4 id="注意"><a href="#注意" class="headerlink" title="注意:"></a>注意:</h4><p>Local模式只能运行一个Spark程序, 如果执行多个Spark程序, 那就是由多个相互独立的Local进程在执行</p>
<p><img src="/../image-local/5..png"></p>
<h1 id="三、Spark-Local基本配置"><a href="#三、Spark-Local基本配置" class="headerlink" title="三、Spark-Local基本配置"></a>三、Spark-Local基本配置</h1><p>###1. 课程服务器环境：<br>使用三台Linux虚拟机服务器来学习, 三台虚拟机的功能分配是:<br>node1: Master(HDFS\YARN\Spark) 和 Worker(HDFS\ YARN\ Spark)<br>node2: Worker(HDFS\ YARN\ Spark)<br>node3: Worker(HDFS\ YARN\ Spark) 和 Hive</p>
<h3 id="2-集群环境的搭建："><a href="#2-集群环境的搭建：" class="headerlink" title="2.集群环境的搭建："></a>2.集群环境的搭建：</h3><p>PYTHON 推荐3.8<br>JDK 1.8<br>操作系统CentOS 7<br>已部署好Hadoop集群(HDFS\YARN) </p>
<p><img src="/../image-local/6.png"></p>
<p><img src="/../image-local/7.png"></p>
<h3 id="3-安装搭建"><a href="#3-安装搭建" class="headerlink" title="3.安装搭建"></a>3.安装搭建</h3><p>本实践的Python环境需要安装到Linux(虚拟机)和Windows(本机)上</p>
<h5 id="3-1-Anaconda-On-Linux-安装"><a href="#3-1-Anaconda-On-Linux-安装" class="headerlink" title="3. 1 Anaconda On Linux 安装"></a>3. 1 Anaconda On Linux 安装</h5><p>安装上传安装包: 上传: 资料中提供的Anaconda3-2021.05-Linux-x86_64.sh文件到Linux服务器上安装:<br>sh .&#x2F;Anaconda3-2021.05-Linux-x86_64.sh</p>
<p><img src="/../image-local/8.png"></p>
<p>安装完成后, 退出终端， 重新进来，看到这个Base开头表明安装好了（base是默认的虚拟环境）。</p>
<h5 id="3-2-Spark安装"><a href="#3-2-Spark安装" class="headerlink" title="3. 2 Spark安装"></a>3. 2 Spark安装</h5><p>（1）解压下载的Spark安装包<br>tar -zxvf spark-3.2.0-bin-hadoop3.2.tgz -C &#x2F;export&#x2F;server&#x2F;</p>
<p><img src="/../image-local/9.png"></p>
<p>（2）由于spark目录名称很⻓, 给其一个软链接:<br>ln -s &#x2F;export&#x2F;server&#x2F;spark-3.2.0-bin-hadoop3.2 &#x2F;export&#x2F;server&#x2F;spark</p>
<p><img src="/../image-local/10.png"></p>
<p>（3）环境变量<br>配置Spark由如下5个环境变量需要设置<br>	SPARK_HOME: 表示Spark安装路径在哪里<br>	PYSPARK_PYTHON: 表示Spark想运行Python程序, 那么去哪里找python执行器<br>	JAVA_HOME: 告知Spark Java在哪里<br>	HADOOP_CONF_DIR: 告知Spark Hadoop的配置文件在哪里<br>	HADOOP_HOME: 告知Spark  Hadoop安装在哪里</p>
<p><img src="/../image-local/11.png"></p>
<h1 id="四、Spark-Local测试训练"><a href="#四、Spark-Local测试训练" class="headerlink" title="四、Spark-Local测试训练"></a>四、Spark-Local测试训练</h1><h2 id="测试一：bin-x2F-pyspark"><a href="#测试一：bin-x2F-pyspark" class="headerlink" title="测试一：bin&#x2F;pyspark"></a>测试一：bin&#x2F;pyspark</h2><p>bin&#x2F;pyspark<br>bin&#x2F;pyspark 程序, 可以提供一个  交互式的 Python解释器环境, 在这里面可以写普通python代码, 以及spark代码</p>
<p><img src="/../image-local/12.png"></p>
<p>在这个环境内, 可以运行spark代码<br>图中的: parallelize 和 map 都是spark提供的API<br>sc.parallelize([1,2,3,4,5]).map(lambda x: x + 1).collect() </p>
<p><img src="/../image-local/13.png"></p>
<h2 id="测试二：WEB-UI-4040"><a href="#测试二：WEB-UI-4040" class="headerlink" title="测试二：WEB UI (4040)"></a>测试二：WEB UI (4040)</h2><p>（1）Spark程序在运行的时候, 会绑定到机器的4040端口上.<br>如果4040端口被占用, 会顺延到4041 … 4042…</p>
<p><img src="/../image-local/14.png"></p>
<p>（2）4040端口是一个WEBUI端口, 可以在浏览器内打开:</p>
<p><img src="/../image-local/15.png"></p>
<p>（3）打开监控页面后, 可以发现 在程序内仅有一个Driver<br>因为我们是Local模式, Driver即管理 又 干活.<br>同时, 输入jps</p>
<p><img src="/../image-local/16.png"></p>
<p>可以看到local模式下的唯一进程存在，这个进程 即是master也是worker</p>
<h2 id="测试三：bin-x2F-spark-submit-PI"><a href="#测试三：bin-x2F-spark-submit-PI" class="headerlink" title="测试三：bin&#x2F;spark-submit (PI)"></a>测试三：bin&#x2F;spark-submit (PI)</h2><p>作用: 提交指定的Spark代码到Spark环境中运行这个仅作为了解即可, 因为这个是用于scala语言的解释器环境<br>bin&#x2F;spark-submit (PI)<br>作用: 提交指定的Spark代码到Spark环境中运行<br>使用方法:<br>语法：bin&#x2F;spark-submit [可选的一些选项] jar包或者python代码的路径 [代码的参数]<br>示例：bin&#x2F;spark-submit &#x2F;export&#x2F;server&#x2F;spark&#x2F;examples&#x2F;src&#x2F;main&#x2F;python&#x2F;pi.py 10<br>此案例 运行Spark官方所提供的示例代码 来计算圆周率值.  后面的10 是主函数接受的参数, 数字越高, 计算圆周率越准确.</p>
<p><img src="/../image-local/17.png"></p>
<h2 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h2><p><img src="/../image-local/18.png"></p>
<p>了解：bin&#x2F;spark-shell<br>同样是一个解释器环境, 和bin&#x2F;pyspark不同的是, 这个解释器环境 运行的不是python代码, 而是scala程序代码</p>
<p><img src="/../image-local/19.png"></p>
<p>如上图，在不是合适的地方无法识别语法准确，这个仅作为了解即可, 因为这个是用于scala语言的解释器环境</p>
<h1 id="五、Spark-Local总结"><a href="#五、Spark-Local总结" class="headerlink" title="五、Spark-Local总结"></a>五、Spark-Local总结</h1><p>Local模式就是以一个独立进程配合其内部线程来提供完成Spark运行时环境Local模式可以通过spark-shell&#x2F;pyspark&#x2F;spark-submit等来开启。是一个交互式的解释器执行环境环境启动后就得到了一个LocalSpark环境可以运行Python代码去进行Spark计算，类似Python自带解释器。</p>
<p>Spark的任务在运行后，会在Driver所在机器绑定到4040端口提供当前任务的监控页面供查看。</p>
<h3 id="综上："><a href="#综上：" class="headerlink" title="综上："></a>综上：</h3><p>Spark local模式被称为Local模式，是用单机的多个线程来模拟Spark分布式计算，通常用来验证开发出来的应用程序逻辑上有没有问题，运行该模式使用简单，速度快、通用性强，只需要把Spark的安装包解压后，改一些常用的配置即可使用，而不用启动Spark的Master、Worker守护进程，也不用启动Hadoop的各服务，这是和其他模式的区别哦，要记住才能理解。</p>
]]></content>
  </entry>
  <entry>
    <title>Sqoop配置文档</title>
    <url>/2023/06/19/Sqoop%E9%85%8D%E7%BD%AE%E6%96%87%E6%A1%A3/</url>
    <content><![CDATA[<h1 id="Sqoop配置"><a href="#Sqoop配置" class="headerlink" title="Sqoop配置"></a>Sqoop配置</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>前提</p>
<p>安装sqoop的前提是已经具备java、mysql、hadoop和hive环境。</p>
<h5 id="配置文件修改"><a href="#配置文件修改" class="headerlink" title="配置文件修改"></a>配置文件修改</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vim /etc/profile，将以下内容添加进去</span><br><span class="line"></span><br><span class="line">#SQOOP_HOME</span><br><span class="line">export SQOOP_HOME=/export/server/sqoop</span><br><span class="line">export PATH=$PATH:$SQOOP_HOME/bin</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/1.jpg" alt="图 1">  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">进入到$SQOOP_HOME/conf</span><br><span class="line">将sqoop-env-template.sh修改成sqoop-env.sh</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/2.jpg" alt="图 2"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">编辑sqoop-env.sh文件，添加以下内容</span><br><span class="line">export HADOOP_COMMON_HOME= /export/server/hadoop</span><br><span class="line">export HADOOP_MAPRED_HOME= /export/server/hadoop</span><br><span class="line">export HIVE_HOME= /export/server/hive</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/3.jpg" alt="图 3"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">加入mysql的jdbc驱动包</span><br><span class="line">cp /export/server/hive/lib/mysql-connector-java-5.1.32.jar $SQOOP_HOME/lib/</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/4.jpg" alt="图 4"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">验证启动</span><br><span class="line">bin/sqoop list-databases \</span><br><span class="line"> --connect jdbc:mysql://node1:3306/ \</span><br><span class="line"> --username root --password hadoop</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/5.jpg" alt="图 5"></p>
<h2 id="Sqoop导入"><a href="#Sqoop导入" class="headerlink" title="Sqoop导入"></a>Sqoop导入</h2><p><strong>Sqoop测试表数据</strong><br>在mysql中创建数据库userdb<code>，然后执行参考资料中的sql脚本： 创建三张表: emp雇员表emp_add</code>雇员地址表emp_conn雇员联系表。<br><img src="/../image-sqoop/6.jpg" alt="图 6"></p>
<h5 id="全量导入mysql表数据到HDFS"><a href="#全量导入mysql表数据到HDFS" class="headerlink" title="全量导入mysql表数据到HDFS"></a>全量导入mysql表数据到HDFS</h5><p>下面的命令用于从MySQL数据库服务器中的emp表导入HDFS。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example1-mysql-hdfs-start</span><br><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--delete-target-dir \</span><br><span class="line">--target-dir /sqoop/sqoopresult \</span><br><span class="line">--table emp --m 1</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/7.jpg" alt="图 7"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example2-mysql-hdfs-terminated</span><br><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--target-dir /sqoop/sqoopresult2 \</span><br><span class="line">--fields-terminated-by &#x27;\t&#x27; \</span><br><span class="line">--table emp --m 1</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/8.jpg" alt="图 8"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example3-mysql-hdfs-split</span><br><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--target-dir /sqoop/sqoopresult3 \</span><br><span class="line">--fields-terminated-by &#x27;\t&#x27; \</span><br><span class="line">--split-by id \</span><br><span class="line">--table emp --m 2</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/9.jpg" alt="图 9"></p>
<h5 id="全量导入mysql表数据到HIVE"><a href="#全量导入mysql表数据到HIVE" class="headerlink" title="全量导入mysql表数据到HIVE"></a>全量导入mysql表数据到HIVE</h5><h6 id="方式一：先复制表结构到hive中再导入数据"><a href="#方式一：先复制表结构到hive中再导入数据" class="headerlink" title="方式一：先复制表结构到hive中再导入数据"></a>方式一：先复制表结构到hive中再导入数据</h6><p>在hive中新建数据库sqoop_test用于测试</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">create database if not exists sqoop_test comment &quot;this is sqoop db&quot; with dbproperties(&#x27;createdBy&#x27;=&#x27;yzl&#x27;);</span><br><span class="line"></span><br><span class="line">use sqoop_test;</span><br><span class="line"></span><br><span class="line">show tables;</span><br><span class="line"></span><br><span class="line">desc formatted emp_add_sp;</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/10.jpg" alt="图 10"><br><img src="/../image-sqoop/11.jpg" alt="图 11"><br>将关系型数据的表结构复制到hive中</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example4-1-mysql-hive-structure</span><br><span class="line">bin/sqoop create-hive-table \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--table emp_add \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--hive-table sqoop_test.emp_add_sp</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/12.jpg" alt="图 12"></p>
<p>从关系数据库导入文件到hive中</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example4-2-mysql-hive-data</span><br><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--table emp_add \</span><br><span class="line">--hive-table sqoop_test.emp_add_sp \</span><br><span class="line">--hive-import \</span><br><span class="line">--m 1</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/13.jpg" alt="图 13"></p>
<h6 id="方式二：直接复制表结构数据到hive中"><a href="#方式二：直接复制表结构数据到hive中" class="headerlink" title="方式二：直接复制表结构数据到hive中"></a>方式二：直接复制表结构数据到hive中</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example5-mysql-hive</span><br><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--table emp_conn \</span><br><span class="line">--hive-import \</span><br><span class="line">--m 1 \</span><br><span class="line">--hive-database sqoop_test;</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/14.jpg" alt="图 14"><br><img src="/../image-sqoop/15.jpg" alt="图 15"></p>
<h5 id="导入表数据子集-where过滤"><a href="#导入表数据子集-where过滤" class="headerlink" title="导入表数据子集(where过滤)"></a>导入表数据子集(where过滤)</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example6-mysql-hdfs-where</span><br><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--where &quot;city =&#x27;sec-bad&#x27;&quot; \</span><br><span class="line">--target-dir /sqoop/wherequery \</span><br><span class="line">--table emp_add --m 1</span><br></pre></td></tr></table></figure>
<h5 id="导入表数据子集-query查询"><a href="#导入表数据子集-query查询" class="headerlink" title="导入表数据子集(query查询)"></a>导入表数据子集(query查询)</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example7-mysql-hdfs-query</span><br><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--target-dir /sqoop/wherequery2 \</span><br><span class="line">--query &#x27;select id,name,deg from emp WHERE  id&gt;1203 and $CONDITIONS&#x27; \</span><br><span class="line">--split-by id \</span><br><span class="line">--fields-terminated-by &#x27;\001&#x27; \</span><br><span class="line">--m 2</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/16.jpg" alt="图 16"></p>
<h5 id="Append模式增量导入"><a href="#Append模式增量导入" class="headerlink" title="Append模式增量导入"></a>Append模式增量导入</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example8-1-mysql-hdfs-append</span><br><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--target-dir /sqoop/appendresult \</span><br><span class="line">--table emp --m 1</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/17.jpg" alt="图 17"></p>
<p>使用hdfs dfs -cat查看生成的数据文件，发现数据已经导入到hdfs中</p>
<p>然后在mysql的emp表中插入2条数据:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">insert into `userdb`.`emp` (`id`, `name`, `deg`, `salary`, `dept`) values (&#x27;1206&#x27;, &#x27;allen&#x27;, &#x27;admin&#x27;, &#x27;30000&#x27;, &#x27;tp&#x27;);</span><br><span class="line">insert into `userdb`.`emp` (`id`, `name`, `deg`, `salary`, `dept`) values (&#x27;1207&#x27;, &#x27;woon&#x27;, &#x27;admin&#x27;, &#x27;40000&#x27;, &#x27;tp&#x27;);</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/18.jpg" alt="图 18"><br>执行如下的指令，实现增量的导入:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example8-2-mysql-hdfs-append</span><br><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--table emp --m 1 \</span><br><span class="line">--target-dir /sqoop/appendresult \</span><br><span class="line">--incremental append \</span><br><span class="line">--check-column id \</span><br><span class="line">--last-value 1205</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/19.jpg" alt="图 19"></p>
<h6 id="Lastmodified模式增量导入"><a href="#Lastmodified模式增量导入" class="headerlink" title="Lastmodified模式增量导入"></a>Lastmodified模式增量导入</h6><p>首先创建一个customer表，指定一个时间戳字段</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">create table customertest(id int,name varchar(20),last_mod timestamp default current_timestamp on update current_timestamp);</span><br></pre></td></tr></table></figure>
<p>插入如下记录</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">insert into customertest(id,name) values(1,&#x27;neil&#x27;);</span><br><span class="line">insert into customertest(id,name) values(2,&#x27;jack&#x27;);</span><br><span class="line">insert into customertest(id,name) values(3,&#x27;martin&#x27;);</span><br><span class="line">insert into customertest(id,name) values(4,&#x27;tony&#x27;);</span><br><span class="line">insert into customertest(id,name) values(5,&#x27;eric&#x27;);</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/20.jpg" alt="图 20"><br>此时执行sqoop指令将数据导入hdfs</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example9-1-mysql-hdfs-Lastmodified</span><br><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--target-dir /sqoop/lastmodifiedresult \</span><br><span class="line">--table customertest --m 1</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/21.jpg" alt="图 21"><br><img src="/../image-sqoop/22.jpg" alt="图 22"><br>再次插入一条数据进入customertest表</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">insert into customertest(id,name) values(6,&#x27;james&#x27;)</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/23.jpg" alt="图 23"><br>使用incremental的方式进行增量的导入</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example9-2-mysql-hdfs-Lastmodified</span><br><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--table customertest \</span><br><span class="line">--target-dir /sqoop/lastmodifiedresult \</span><br><span class="line">--check-column last_mod \</span><br><span class="line">--incremental lastmodified \</span><br><span class="line">--last-value &quot;2019-05-28 18:42:06&quot; \</span><br><span class="line">--m 1 \</span><br><span class="line">--append</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/24.jpg" alt="图 24"><br><img src="/../image-sqoop/25.jpg" alt="图 25"></p>
<h6 id="Lastmodified模式-append、merge-key"><a href="#Lastmodified模式-append、merge-key" class="headerlink" title="Lastmodified模式:append、merge-key"></a>Lastmodified模式:append、merge-key</h6><p>我们去更新 id为1的name字段</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">update customertest set name = &#x27;Neil&#x27; where id = 1;</span><br></pre></td></tr></table></figure>
<p>执行如下指令，把id字段作为merge-key</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example10-mysql-hdfs-merge-key</span><br><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--table customertest \</span><br><span class="line">--target-dir /sqoop/lastmodifiedresult \</span><br><span class="line">--check-column last_mod \</span><br><span class="line">--incremental lastmodified \</span><br><span class="line">--last-value &quot;2019-05-28 18:42:06&quot; \</span><br><span class="line">--m 1 \</span><br><span class="line">--merge-key id</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/26.jpg" alt="图 26"></p>
<h2 id="Sqoop导出"><a href="#Sqoop导出" class="headerlink" title="Sqoop导出"></a>Sqoop导出</h2><h5 id="默认模式导出HDFS数据到mysql"><a href="#默认模式导出HDFS数据到mysql" class="headerlink" title="默认模式导出HDFS数据到mysql"></a>默认模式导出HDFS数据到mysql</h5><h6 id="准备HDFS数据"><a href="#准备HDFS数据" class="headerlink" title="准备HDFS数据"></a>准备HDFS数据</h6><p>在HDFS文件系统中“&#x2F;emp&#x2F;”目录的下创建一个文件emp_data.txt</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir /export/data/sqoop-data/emp/</span><br><span class="line"></span><br><span class="line">vim emp_data.txt</span><br><span class="line"></span><br><span class="line">1201,gopal,manager,50000,TP</span><br><span class="line">1202,manisha,preader,50000,TP</span><br><span class="line">1203,kalil,php dev,30000,AC</span><br><span class="line">1204,prasanth,php dev,30000,AC</span><br><span class="line">1205,kranthi,admin,20000,TP</span><br><span class="line">1206,satishp,grpdes,20000,GR</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/27.jpg" alt="图 27"><br><img src="/../image-sqoop/28.jpg" alt="图 28"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#上传至hdfs</span><br><span class="line">hadoop fs -mkdir /sqoop/emp_data</span><br><span class="line">hadoop fs -put emp_data.txt /sqoop/emp_data </span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/29.jpg" alt="图 29"></p>
<h6 id="手动创建mysql中的目标表"><a href="#手动创建mysql中的目标表" class="headerlink" title="手动创建mysql中的目标表"></a>手动创建mysql中的目标表</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; use userdb;</span><br><span class="line">mysql&gt; create table employee ( </span><br><span class="line">   id int not null primary key, </span><br><span class="line">   name varchar(20), </span><br><span class="line">   deg varchar(20),</span><br><span class="line">   salary int,</span><br><span class="line">   dept varchar(10));</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/30.jpg" alt="图 30"></p>
<h6 id="执行导出命令"><a href="#执行导出命令" class="headerlink" title="执行导出命令"></a>执行导出命令</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example10-hdfs-mysql-export</span><br><span class="line">bin/sqoop export \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--table employee1 \</span><br><span class="line">--columns id,name,deg,salary,dept \</span><br><span class="line">--export-dir /sqoop/emp_data/</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/31.jpg" alt="图 31"></p>
<h5 id="更新导出（updateonly模式）"><a href="#更新导出（updateonly模式）" class="headerlink" title="更新导出（updateonly模式）"></a>更新导出（updateonly模式）</h5><h6 id="准备HDFS数据-1"><a href="#准备HDFS数据-1" class="headerlink" title="准备HDFS数据"></a>准备HDFS数据</h6><p>在HDFS文件系统中&#x2F;sqoop&#x2F;updateonly_1&#x2F;目录的下创建一个文件updateonly_1.txt</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1201,gopal,manager,50000</span><br><span class="line">1202,manisha,preader,50000</span><br><span class="line">1203,kalil,php dev,30000</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/32.jpg" alt="图 32"></p>
<h6 id="手动创建mysql中的目标表-1"><a href="#手动创建mysql中的目标表-1" class="headerlink" title="手动创建mysql中的目标表"></a>手动创建mysql中的目标表</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; USE userdb;</span><br><span class="line">mysql&gt; CREATE TABLE updateonly ( </span><br><span class="line">   id INT NOT NULL PRIMARY KEY, </span><br><span class="line">   name VARCHAR(20), </span><br><span class="line">   deg VARCHAR(20),</span><br><span class="line">   salary INT);</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/33.jpg" alt="图 33"></p>
<h6 id="先执行全部导出操作"><a href="#先执行全部导出操作" class="headerlink" title="先执行全部导出操作"></a>先执行全部导出操作</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example11-1-hdfs-mysql-export-updateonly</span><br><span class="line">bin/sqoop export \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--table updateonly \</span><br><span class="line">--export-dir /sqoop/updateonly_1/</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/34.jpg" alt="图 34"></p>
<h6 id="新增一个文件"><a href="#新增一个文件" class="headerlink" title="新增一个文件"></a>新增一个文件</h6><p>新增一个文件updateonly_2.txt：<strong>修改了前三条数据并且新增了一条记录</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1201,gopal,manager,1212</span><br><span class="line">1202,manisha,preader,1313</span><br><span class="line">1203,kalil,php dev,1414</span><br><span class="line">1204,allen,java,1515</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hadoop fs -mkdir /sqoop/updateonly_2</span><br><span class="line">hadoop fs -put updateonly_2.txt /sqoop/updateonly_2</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/35.jpg" alt="图 35"></p>
<h6 id="执行更新导出"><a href="#执行更新导出" class="headerlink" title="执行更新导出"></a>执行更新导出</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example11-2-hdfs-mysql-export-updateonly</span><br><span class="line">bin/sqoop export \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--table updateonly \</span><br><span class="line">--export-dir /sqoop/updateonly_2 \</span><br><span class="line">--update-key id \</span><br><span class="line">--update-mode updateonly</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/37.jpg" alt="图 37"></p>
<h2 id="更新导出（allowinsert模式）"><a href="#更新导出（allowinsert模式）" class="headerlink" title="更新导出（allowinsert模式）"></a>更新导出（allowinsert模式）</h2><h6 id="准备HDFS数据-2"><a href="#准备HDFS数据-2" class="headerlink" title="准备HDFS数据"></a>准备HDFS数据</h6><p>在HDFS &#x2F;sqoop&#x2F;allowinsert_1&#x2F;目录的下创建一个文件allowinsert_1.txt</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1201,gopal,manager,50000</span><br><span class="line">1202,manisha,preader,50000</span><br><span class="line">1203,kalil,php dev,30000</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/38.jpg" alt="图 38"></p>
<h6 id="手动创建mysql中的目标表-2"><a href="#手动创建mysql中的目标表-2" class="headerlink" title="手动创建mysql中的目标表"></a>手动创建mysql中的目标表</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; USE userdb;</span><br><span class="line">mysql&gt; CREATE TABLE allowinsert ( </span><br><span class="line">   id INT NOT NULL PRIMARY KEY, </span><br><span class="line">   name VARCHAR(20), </span><br><span class="line">   deg VARCHAR(20),</span><br><span class="line">   salary INT);</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/39.jpg" alt="图 39"></p>
<h6 id="先执行全部导出操作-1"><a href="#先执行全部导出操作-1" class="headerlink" title="先执行全部导出操作"></a>先执行全部导出操作</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example12-1-hdfs-mysql-export-allowinsert</span><br><span class="line">bin/sqoop export \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--table allowinsert \</span><br><span class="line">--export-dir /sqoop/allowinsert_1/</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/40.jpg" alt="图 40"></p>
<h6 id="新增文件"><a href="#新增文件" class="headerlink" title="新增文件"></a>新增文件</h6><p>创建文件allowinsert_2.txt。修改前三条数据并且新增了一条记录。上传至 &#x2F;sqoop&#x2F;allowinsert_2&#x2F;目录下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1201,gopal,manager,1212</span><br><span class="line">1202,manisha,preader,1313</span><br><span class="line">1203,kalil,php dev,1414</span><br><span class="line">1204,allen,java,1515</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/41.jpg" alt="图 41"></p>
<h6 id="执行更新导出-1"><a href="#执行更新导出-1" class="headerlink" title="执行更新导出"></a>执行更新导出</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example12-2-hdfs-mysql-export-allowinsert</span><br><span class="line">bin/sqoop export \</span><br><span class="line">--connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root --password hadoop \</span><br><span class="line">--table allowinsert \</span><br><span class="line">--export-dir /sqoop/allowinsert_2/ \</span><br><span class="line">--update-key id \</span><br><span class="line">--update-mode allowinsert</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/42.jpg" alt="图 42"></p>
<h2 id="sqoop-job作业介绍"><a href="#sqoop-job作业介绍" class="headerlink" title="sqoop job作业介绍"></a>sqoop job作业介绍</h2><h6 id="job语法"><a href="#job语法" class="headerlink" title="job语法"></a>job语法</h6><p>以下是创建Sqoop作业的语法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ sqoop job (generic-args) (job-args)</span><br><span class="line">   [-- [subtool-name] (subtool-args)]</span><br><span class="line"></span><br><span class="line">$ sqoop-job (generic-args) (job-args)</span><br><span class="line">   [-- [subtool-name] (subtool-args)]</span><br></pre></td></tr></table></figure>
<h6 id="创建job-–create"><a href="#创建job-–create" class="headerlink" title="创建job(–create)"></a>创建job(–create)</h6><p>在这里，我们创建一个名为myjob，这可以从RDBMS表的数据导入到HDFS作业。下面的命令用于创建一个从DB数据库的employee表导入到HDFS文件的作业</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example13-1-mysql-hdfs-job</span><br><span class="line">bin/sqoop job --create myjob -- import --connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password hadoop \</span><br><span class="line">--target-dir /sqoop/sqoopresult555 \</span><br><span class="line">--table emp --m 1</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/43.jpg" alt="图 43"></p>
<h6 id="验证job-–list"><a href="#验证job-–list" class="headerlink" title="验证job (–list)"></a>验证job (–list)</h6><p><strong>‘–list’</strong> 参数是用来验证保存的作业。下面的命令用来验证保存Sqoop作业的列表</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example13-2-mysql-hdfs-job</span><br><span class="line">bin/sqoop job --list</span><br></pre></td></tr></table></figure>
<p>它显示了保存作业列表</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Available jobs: </span><br><span class="line">   myjob</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/44.jpg" alt="图 44"></p>
<h6 id="检查job-–show"><a href="#检查job-–show" class="headerlink" title="检查job(–show)"></a>检查job(–show)</h6><p><strong>‘–show’</strong> 参数用于检查或验证特定的工作，及其详细信息。以下命令和样本输出用来验证一个名为myjob的作业</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example13-3-mysql-hdfs-job</span><br><span class="line">bin/sqoop job --show myjob</span><br></pre></td></tr></table></figure>
<p>它显示了工具和它们的选择，这是使用在myjob中作业情况</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Job: myjob </span><br><span class="line"> Tool: import Options:</span><br><span class="line"> ---------------------------- </span><br><span class="line"> direct.import = true</span><br><span class="line"> codegen.input.delimiters.record = 0</span><br><span class="line"> hdfs.append.dir = false </span><br><span class="line"> db.table = employee</span><br><span class="line"> ...</span><br><span class="line"> incremental.last.value = 1206</span><br><span class="line"> ...</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/45.jpg" alt="图 45"></p>
<h6 id="执行job-–exec"><a href="#执行job-–exec" class="headerlink" title="执行job (–exec)"></a>执行job (–exec)</h6><p><strong>‘–exec’</strong> 选项用于执行保存的作业。下面的命令用于执行保存的作业称为myjob</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example13-4-mysql-hdfs-job</span><br><span class="line">bin/sqoop job --exec myjob</span><br></pre></td></tr></table></figure>
<p>它会显示下面的输出</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">10/08/19 13:08:45 INFO tool.CodeGenTool: Beginning code generation </span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/46.jpg" alt="图 46"></p>
<h6 id="job的免密输入"><a href="#job的免密输入" class="headerlink" title="job的免密输入"></a>job的免密输入</h6><p>sqoop在创建job时，使用–password-file参数，可以避免输入mysql密码，如果使用–password将出现警告，并且每次都要手动输入密码才能执行job，<strong>sqoop规定密码文件必须存放在HDFS上，并且权限必须是400</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo -n &quot;hadoop&quot; &gt; node1-mysql.pwd</span><br><span class="line">hadoop fs -mkdir -p /sqoop/pwd/</span><br><span class="line">hadoop fs -put node1-mysql.pwd /sqoop/pwd/</span><br><span class="line">hadoop fs -chmod 400 /sqoop/pwd/node1-mysql.pwd</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/47.jpg" alt="图 47"></p>
<p><strong>检查sqoop的sqoop-site.xml是否存在如下配置</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;sqoop.metastore.client.record.password&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;If true, allow saved passwords in the metastore.</span><br><span class="line">    &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/48.jpg" alt="图 48"></p>
<p><strong>创建sqoop job</strong><br>在创建job时，使用–password-file参数</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example14-1-mysql-hdfs-job-nopwd</span><br><span class="line">bin/sqoop job --create myjob2 -- import --connect jdbc:mysql://node1:3306/userdb \</span><br><span class="line">--username root \</span><br><span class="line">--password-file /sqoop/pwd/node1-mysql.pwd \</span><br><span class="line">--target-dir /sqoop/sqoopresult666 \</span><br><span class="line">--table emp --m 1</span><br></pre></td></tr></table></figure>
<p><img src="/../image-sqoop/49.jpg" alt="图 49"></p>
<p><strong>执行job</strong><br>通过命令</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example14-2-mysql-hdfs-job-nopwd</span><br><span class="line">sqoop job -exec myjob2</span><br></pre></td></tr></table></figure>

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Sqoop的安装的前提是要将Java、mysql、hadoop、hive</span><br><span class="line">环境配置完成，如果这些环境没有配置的话sqoop将没有办法进行安装。</span><br><span class="line">一开始在创建emp表时，需要用到navicat软件，</span><br><span class="line">在下载并激活完成之后并不知道要如何进行连接，在查询并观看视频学习之后才了解到。</span><br><span class="line">在sqoop导入数据库时遇到了ERROR manager.SqlManager: Error executing statement的问题，</span><br><span class="line">在查询了很长的时间才得到解决。总的来说这次作业还是可以让人学到不少的东西的。</span><br></pre></td></tr></table></figure>]]></content>
  </entry>
  <entry>
    <title>Flume教程</title>
    <url>/2023/06/16/flume%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="一、Flume安装"><a href="#一、Flume安装" class="headerlink" title="一、Flume安装"></a>一、Flume安装</h1><p>Flume下载页面：<a href="http://flume.apache.org/download.html">http://flume.apache.org/download.html</a><br><img src="/../image-flume/1.png" alt="1.png"></p>
<p>将<a href="http://www.apache.org/dyn/closer.lua/flume/1.9.0/apache-flume-1.9.0-bin.tar.gz"> apache-flume-1.9.0-bin.tar.gz</a>下载到CentOS系统中，对其解压</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解压命令</span></span><br><span class="line">tar xzf apache-flume-1.9.0-bin.tar.gz</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">添加软连接</span></span><br><span class="line">ln -s apache-flume-1.9.0-bin flume</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Flume使用需要依赖JDK1.8以上环境，确保已安装</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将Flume安装目录配置到PATH中，方便在任意目录使用</span></span><br><span class="line">vi /etc/profile</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">添加以下内容</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">FLUME_HOME</span></span><br><span class="line">export FLUME_HOME=/export/server/flume</span><br><span class="line">export PATH=$PATH:$FLUME_HOME/bin</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">保存成功后刷新</span></span><br><span class="line">source /etc/profile</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看是否设置成功</span></span><br><span class="line">echo $FLUME_HOME</span><br></pre></td></tr></table></figure>
<p><img src="/../image-flume/2.png" alt="2.png"><br><img src="/../image-flume/3.png" alt="3.png"></p>
<h1 id="二、入门使用示例"><a href="#二、入门使用示例" class="headerlink" title="二、入门使用示例"></a>二、入门使用示例</h1><h2 id="案例说明"><a href="#案例说明" class="headerlink" title="案例说明"></a>案例说明</h2><p>使用Flume监听某个端口，使用Netcat向这个端口发送数据，Flume将接收到的数据打印到控制台。</p>
<p><code>Netcat是一款TCP/UDP测试工具</code>，可以通过以下命令安装</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y nc</span><br></pre></td></tr></table></figure>
<p><img src="/../image-flume/4.png" alt="4.png"></p>
<h2 id="添加配置文件"><a href="#添加配置文件" class="headerlink" title="添加配置文件"></a>添加配置文件</h2><p>在flume&#x2F;myconf目录下添加配置文件netcat-logger.conf</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># example1-netcat-logger.conf: 单节点Flume配置</span></span><br><span class="line"><span class="comment"># 定义agent名称为a1</span></span><br><span class="line"><span class="comment"># 设置3个组件的名称</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 配置source类型为NetCat,监听地址为本机，端口为44444</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">netcat</span></span><br><span class="line"><span class="attr">a1.sources.r1.bind</span> = <span class="string">0.0.0.0</span></span><br><span class="line"><span class="attr">a1.sources.r1.port</span> = <span class="string">44444</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#source和channel关联</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 配置channel类型为内存，内存队列最大容量为1000，一个事务中从source接收的Events数量或者发送给sink的Events数量最大为100</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">100</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 配置sink类型为Logger</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">logger</span></span><br><span class="line"><span class="comment"># 将sink绑定到channel上</span></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br></pre></td></tr></table></figure>
<h2 id="启动flume"><a href="#启动flume" class="headerlink" title="启动flume"></a>启动flume</h2><p>查看Flume使用命令</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">flume-ng help</span><br></pre></td></tr></table></figure>
<p>启动agent</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">`flume-ng agent -n a1 -c conf -f example.conf -Dflume.root.logger=INFO,console`</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 使用Netcat测试</span></span></span><br><span class="line"></span><br><span class="line">从另一个终端启动Netcat连接到44444端口，发送一些字符串</span><br><span class="line"></span><br><span class="line">```shell</span><br><span class="line">nc node1 44444</span><br></pre></td></tr></table></figure>
<p><img src="/../image-flume/5.png" alt="5.png"></p>
<p>观察agent控制台<br><img src="/../image-flume/6.png" alt="6.png"></p>
<h2 id="exec-source测试"><a href="#exec-source测试" class="headerlink" title="exec_source测试"></a>exec_source测试</h2><h2 id="配置文件："><a href="#配置文件：" class="headerlink" title="配置文件："></a><strong>配置文件：</strong></h2><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># example2-exec-source-logger.conf</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">exec</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sources.r1.command</span> = <span class="string">tail -F /export/data/flume-example-data/shell/access.log </span></span><br><span class="line"><span class="attr">a1.sources.r1.batchSize</span> = <span class="string">100</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">100</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">logger</span></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br></pre></td></tr></table></figure>
<p><img src="/../image-flume/7.png" alt="7.png"></p>
<h2 id="启动测试："><a href="#启动测试：" class="headerlink" title="启动测试："></a><strong>启动测试：</strong></h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">1.准备一个日志文件</span><br><span class="line">2.写一个脚本模拟往日志文件中持续写入数据</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> &#123;1..10000&#125;; </span><br><span class="line"><span class="keyword">do</span> <span class="built_in">echo</span> <span class="variable">$&#123;i&#125;</span> “bigdata <span class="built_in">log</span>”  &gt;&gt;  access.log ; </span><br><span class="line"><span class="built_in">sleep</span> 0.5; </span><br><span class="line"><span class="keyword">done</span></span><br><span class="line">3.创建一个flume自定义配置文件</span><br><span class="line">4.启动flume采集</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/flume-ng agent -n a1 -c conf/ -f myconf/example2-exec-source-logger.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>
<p><img src="/../image-flume/8.png" alt="8.png"><br><img src="/../image-flume/9.png" alt="9.png"></p>
<h2 id="spooldir-source测试"><a href="#spooldir-source测试" class="headerlink" title="spooldir_source测试"></a>spooldir_source测试</h2><h2 id="配置文件：-1"><a href="#配置文件：-1" class="headerlink" title="配置文件："></a><strong>配置文件：</strong></h2><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment">#example3-spooldir-source.conf</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">spooldir</span></span><br><span class="line"><span class="attr">a1.sources.r1.spoolDir</span> = <span class="string">/export/data/flume-example-data/weblog </span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="string">1000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">100</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">logger</span></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br></pre></td></tr></table></figure>
<p><img src="/../image-flume/10.png" alt="10.png"></p>
<h2 id="启动测试：-1"><a href="#启动测试：-1" class="headerlink" title="启动测试："></a><strong>启动测试：</strong></h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bin/flume-ng agent -n a1 -c conf -f myconf/example3-spooldir-source.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>

<p>注意：spooldir source 与exec source不同，spooldir source本身是可靠的，会记录崩溃之前的采集位置。<br><img src="/../image-flume/11.png" alt="11.png"></p>
<h1 id="taildir-source测试"><a href="#taildir-source测试" class="headerlink" title="taildir_source测试"></a>taildir_source测试</h1><h2 id="配置文件：-2"><a href="#配置文件：-2" class="headerlink" title="配置文件："></a><strong>配置文件：</strong></h2><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment">#example4-taildir-source.conf</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">TAILDIR</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sources.r1.positionFile</span> = <span class="string">/export/data/flume-example-data/flumedata/taildir_position.json</span></span><br><span class="line"><span class="attr">a1.sources.r1.filegroups</span> = <span class="string">g1 g2</span></span><br><span class="line"><span class="attr">a1.sources.r1.filegroups.g1</span> = <span class="string">/export/data/flume-example-data/weblog/web.*</span></span><br><span class="line"><span class="attr">a1.sources.r1.filegroups.g2</span> = <span class="string">/export/data/flume-example-data/wxlog/wx.*</span></span><br><span class="line"><span class="attr">a1.sources.r1.fileHeader</span> = <span class="string">true</span></span><br><span class="line"><span class="comment">#动态的header-keys eg：filepath=/../../../</span></span><br><span class="line"><span class="attr">a1.sources.r1.fileHeaderKey</span> = <span class="string">filepath</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#写死的header-keys（静态的） eg:a1 = aa1</span></span><br><span class="line"><span class="attr">a1.sources.r1.headers.g1.a1</span> = <span class="string">aa1</span></span><br><span class="line"><span class="attr">a1.sources.r1.headers.g1.b1</span> = <span class="string">bb1</span></span><br><span class="line"><span class="attr">a1.sources.r1.headers.g2.a2</span> = <span class="string">aa2</span></span><br><span class="line"><span class="attr">a1.sources.r1.headers.g2.b2</span> = <span class="string">bb2</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sources.r1.maxBatchCount</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="string">10000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">1000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">logger</span></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="启动测试：-2"><a href="#启动测试：-2" class="headerlink" title="启动测试："></a><strong>启动测试：</strong></h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/flume-ng agent -n a1 -c conf/ -f  myconf/example4-taildir-source.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>
<p><img src="/../image-flume/12.png" alt="12.png"></p>
<h1 id="Avro-source测试"><a href="#Avro-source测试" class="headerlink" title="Avro source测试"></a>Avro source测试</h1><h2 id="配置文件：-3"><a href="#配置文件：-3" class="headerlink" title="配置文件："></a><strong>配置文件：</strong></h2><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment">#example5-avro-source.conf</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">avro</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sources.r1.bind</span> = <span class="string">0.0.0.0</span></span><br><span class="line"><span class="attr">a1.sources.r1.port</span> = <span class="string">4141</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="string">200</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="string">100</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">logger</span></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br></pre></td></tr></table></figure>

<p><img src="/../image-flume/13.png" alt="13.png"></p>
<h2 id="启动测试：-3"><a href="#启动测试：-3" class="headerlink" title="启动测试："></a><strong>启动测试：</strong></h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">启动agent：</span><br><span class="line"></span><br><span class="line">bin/flume-ng agent -c conf -f  myconf/example5-avro-source.conf -n a1 -Dflume.root.logger=INFO,console  </span><br><span class="line"></span><br><span class="line">新建avro-log.txt，用一个客户端去给启动好的source发送avro序列化数据：</span><br><span class="line"></span><br><span class="line">bin/flume-ng avro-client --host node1  --port 4141  -F /export/data/flume-example-data/avro-log.txt</span><br></pre></td></tr></table></figure>
<p><img src="/../image-flume/14.png" alt="14.png"><br><img src="/../image-flume/15.png" alt="15.png"></p>
]]></content>
  </entry>
  <entry>
    <title>hive教程</title>
    <url>/2023/06/14/hive%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="Hive3安装"><a href="#Hive3安装" class="headerlink" title="Hive3安装"></a>Hive3安装</h1><h2 id="一、Mysql安装"><a href="#一、Mysql安装" class="headerlink" title="一、Mysql安装"></a>一、Mysql安装</h2><ul>
<li><p>卸载Centos7自带的mariadb</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@node1 ~]# rpm -qa|grep mariadb</span><br><span class="line">mariadb-libs-5.5.64-1.el7.x86_64</span><br><span class="line"></span><br><span class="line">[root@node1 ~]# rpm -e mariadb-libs-5.5.64-1.el7.x86_64 --nodeps</span><br><span class="line">[root@node1 ~]# rpm -qa|grep mariadb                            </span><br><span class="line">[root@node1 ~]# </span><br></pre></td></tr></table></figure>
<p><img src="/../zhangimg/hive1.png" alt="hive1"></p>
</li>
<li><p>安装mysql</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir /export/server/mysql</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">上传mysql-5.7.29-1.el7.x86_64.rpm-bundle.tar 到上述文件夹下  解压</span></span><br><span class="line">tar xvf mysql-5.7.29-1.el7.x86_64.rpm-bundle.tar</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">执行安装</span></span><br><span class="line">yum -y install libaio</span><br><span class="line"></span><br><span class="line"> [root@node1 mysql]rpm -ivh mysql-community-common-5.7.29-1.el7.x86_64.rpm mysql-community-libs-5.7.29-1.el7.x86_64.rpm mysql-community-client-5.7.29-1.el7.x86_64.rpm mysql-community-server-5.7.29-1.el7.x86_64.rpm </span><br><span class="line"></span><br><span class="line">warning: mysql-community-common-5.7.29-1.el7.x86_64.rpm: Header V3 DSA/SHA1 Signature, key ID 5072e1f5: NOKEY</span><br><span class="line">Preparing...                          ################################# [100%]</span><br><span class="line">Updating / installing...</span><br><span class="line">   1:mysql-community-common-5.7.29-1.e################################# [ 25%]</span><br><span class="line">   2:mysql-community-libs-5.7.29-1.el7################################# [ 50%]</span><br><span class="line">   3:mysql-community-client-5.7.29-1.e################################# [ 75%]</span><br><span class="line">   4:mysql-community-server-5.7.29-1.e################                  ( 49%)</span><br></pre></td></tr></table></figure>
<p><img src="/../zhangimg/hive2.png" alt="hive2"><br><img src="/../zhangimg/hive3.png" alt="hive3"><br><img src="/../zhangimg/hive4.png" alt="hive4"><br><img src="/../zhangimg/hive5.png" alt="hive5"></p>
</li>
<li><p>mysql初始化设置</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">初始化</span></span><br><span class="line">mysqld --initialize</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">更改所属组</span></span><br><span class="line">chown mysql:mysql /var/lib/mysql -R</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">启动mysql</span></span><br><span class="line">systemctl start mysqld.service</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">查看生成的临时root密码</span></span><br><span class="line">cat  /var/log/mysqld.log</span><br><span class="line"></span><br><span class="line">[Note] A temporary password is generated for root@localhost: o+TU+KDOm004</span><br></pre></td></tr></table></figure>
<p><img src="/../zhangimg/hive6.png" alt="hive6"><br><img src="/../zhangimg/hive7.png" alt="hive7"><br><img src="/../zhangimg/hive8.png" alt="hive8"><br><img src="/../zhangimg/hive9.png" alt="hive9"></p>
</li>
<li><p>修改root密码 授权远程访问 设置开机自启动</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@node1 ~]# mysql -u root -p</span><br><span class="line">Enter password:     #这里输入在日志中生成的临时密码</span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 3</span><br><span class="line">Server version: 5.7.29</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type &#x27;help;&#x27; or &#x27;\h&#x27; for help. Type &#x27;\c&#x27; to clear the current input statement.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"></span><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">更新root密码  设置为hadoop</span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">alter user user() identified by <span class="string">&quot;hadoop&quot;</span>;</span></span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">授权</span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">use mysql;</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">GRANT ALL PRIVILEGES ON *.* TO <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED BY <span class="string">&#x27;hadoop&#x27;</span> WITH GRANT OPTION;</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">FLUSH PRIVILEGES;</span> </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">mysql的启动和关闭 状态查看 （这几个命令必须记住）</span></span><br><span class="line">systemctl stop mysqld</span><br><span class="line">systemctl status mysqld</span><br><span class="line">systemctl start mysqld</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">建议设置为开机自启动服务</span></span><br><span class="line">[root@node1 ~]# systemctl enable  mysqld                             </span><br><span class="line">Created symlink from /etc/systemd/system/multi-user.target.wants/mysqld.service to /usr/lib/systemd/system/mysqld.service.</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<p> <img src="/../zhangimg/hive10.png" alt="hive10"><br> <img src="/../zhangimg/hive11.png" alt="hive11"><br> <img src="/../zhangimg/hive12.png" alt="hive12"><br> <img src="/../zhangimg/hive13.png" alt="hive13"><br> <img src="/../zhangimg/hive14.png" alt="hive14"></p>
<h2 id="二、Hive的安装"><a href="#二、Hive的安装" class="headerlink" title="二、Hive的安装"></a>二、Hive的安装</h2><ul>
<li><p>上传安装包 解压</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar zxvf apache-hive-3.1.2-bin.tar.gz</span><br><span class="line">ln -s apache-hive-3.1.2-bin hive</span><br></pre></td></tr></table></figure>
</li>
<li><p>解决Hive与Hadoop之间guava版本差异</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /export/server/hive/</span><br><span class="line">rm -rf lib/guava-19.0.jar</span><br><span class="line">cp /export/server/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar ./lib/</span><br></pre></td></tr></table></figure></li>
</ul>
<p> <img src="/../zhangimg/hive15.png" alt="hive10"><br>  <img src="/../zhangimg/hive16.png" alt="hive16"><br>  <img src="/../zhangimg/hive17.png" alt="hive17"><br>   <img src="/../zhangimg/hive18.png" alt="hive18"></p>
<ul>
<li><p>修改配置文件</p>
<ul>
<li><p>hive-env.sh</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /export/server/hive/conf</span><br><span class="line">mv hive-env.sh.template hive-env.sh</span><br><span class="line"></span><br><span class="line">vim hive-env.sh</span><br><span class="line">export HADOOP_HOME=/export/server/hadoop</span><br><span class="line">export HIVE_CONF_DIR=/export/server/hive/conf</span><br><span class="line">export HIVE_AUX_JARS_PATH=/export/server/hive/lib</span><br></pre></td></tr></table></figure>
</li>
<li><p>hive-site.xml</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim hive-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 存储元数据mysql相关配置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://node1:3306/hive3?createDatabaseIfNotExist=true<span class="symbol">&amp;amp;</span>useSSL=false<span class="symbol">&amp;amp;</span>useUnicode=true<span class="symbol">&amp;amp;</span>characterEncoding=UTF-8<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- H2S运行绑定host --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.bind.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>node1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 远程模式部署metastore metastore地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://node1:9083<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 关闭元数据存储授权  --&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.event.db.notification.api.auth<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<p> <img src="/../zhangimg/hive19.png" alt="hive19"><br> <img src="/../zhangimg/hive20.png" alt="hive19"></p>
</li>
<li><p>上传mysql jdbc驱动到hive安装包lib下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql-connector-java-5.1.32.jar</span><br></pre></td></tr></table></figure></li>
</ul>
<p><img src="/../zhangimg/hive21.png" alt="hive20"></p>
<ul>
<li><p>初始化元数据</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /export/server/hive/</span><br><span class="line"></span><br><span class="line">bin/schematool -initSchema -dbType mysql -verbos</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">初始化成功会在mysql中创建74张表</span></span><br></pre></td></tr></table></figure></li>
</ul>
<p><img src="/../zhangimg/hive21.png" alt="hive21"></p>
<ul>
<li><p>在hdfs创建hive存储目录</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hadoop fs -mkdir /tmp</span><br><span class="line">hadoop fs -mkdir -p /user/hive/warehouse</span><br><span class="line">hadoop fs -chmod g+w /tmp</span><br><span class="line">hadoop fs -chmod g+w /user/hive/warehouse</span><br></pre></td></tr></table></figure></li>
</ul>
<p><img src="/../zhangimg/hive22.png" alt="hive22"><br><img src="/../zhangimg/hive23.png" alt="hive23"></p>
<ul>
<li><p>&#x3D;&#x3D;启动hive&#x3D;&#x3D;</p>
</li>
<li><p>1、启动metastore服务</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">前台启动  关闭ctrl+c</span></span><br><span class="line">/export/server/hive/bin/hive --service metastore</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">前台启动开启debug日志</span></span><br><span class="line">/export/server/hive/bin/hive --service metastore --hiveconf hive.root.logger=DEBUG,console  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">后台启动 进程挂起  关闭使用jps+ <span class="built_in">kill</span> -9</span></span><br><span class="line">nohup /export/server/hive/bin/hive --service metastore &amp;</span><br></pre></td></tr></table></figure>
<p><img src="/../zhangimg/hive24.png" alt="hive24"></p>
</li>
<li><p>2、启动hiveserver2服务</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nohup /export/server/hive/bin/hive --service hiveserver2 &amp;</span><br><span class="line"><span class="meta prompt_">  </span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">注意 启动hiveserver2需要一定的时间  不要启动之后立即beeline连接 可能连接不上</span></span><br></pre></td></tr></table></figure></li>
<li><p>3、beeline客户端连接</p>
<ul>
<li>拷贝node1安装包到beeline客户端机器上（node3）</li>
</ul>
 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">scp -r /export/server/apache-hive-3.1.2-bin/ root@node3:/export/server/</span><br></pre></td></tr></table></figure>
<p> <img src="/../zhangimg/hive25.png" alt="hive25"></p>
</li>
<li><p>连接访问</p>
<pre><code>```shell
/export/server/hive/bin/beeline
</code></pre>
<p>  <img src="/../zhangimg/hive26.png" alt="hive26"><br>  <img src="/../zhangimg/hive27.png" alt="hive27"></p>
</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>kafka全流程配置</title>
    <url>/2023/06/16/kafka%E5%85%A8%E6%B5%81%E7%A8%8B%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<h1 id="4-Kafka"><a href="#4-Kafka" class="headerlink" title="4.Kafka"></a>4.Kafka</h1><h2 id="4-1安装Kafka集群"><a href="#4-1安装Kafka集群" class="headerlink" title="4.1安装Kafka集群"></a>4.1安装Kafka集群</h2><h3 id="1-上传安装包至-x2F-export-x2F-server路径下，并解压："><a href="#1-上传安装包至-x2F-export-x2F-server路径下，并解压：" class="headerlink" title="1.	上传安装包至&#x2F;export&#x2F;server路径下，并解压："></a>1.	上传安装包至&#x2F;export&#x2F;server路径下，并解压：</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd  /export/server/ </span><br><span class="line">rz -be</span><br><span class="line">tar -zxvf kafka_2.12-2.4.1.tgz</span><br></pre></td></tr></table></figure>
<p>#设置软连接</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ln -ls kakfa_2.12-2.4.1 kafka</span><br></pre></td></tr></table></figure>
<p><img src="/../kafkaimg/1.png"></p>
<h3 id="4-2修改相关配置文件"><a href="#4-2修改相关配置文件" class="headerlink" title="4.2	修改相关配置文件"></a>4.2	修改相关配置文件</h3><p>#进入配置文件目录</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd /export/server/kafka/config</span><br></pre></td></tr></table></figure>
<p>#编辑server.properties配置文件，添加以下代码：<br>#为依次增长的:0、1、2、3、4,集群中唯一 id –》从0开始，每台不能重复，第一块要改的</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">broker.id=0 </span><br><span class="line">----Logbasic------</span><br></pre></td></tr></table></figure>
<p>#数据存储的目录，第二块要改的</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">log.dirs=/export/data/kafka-logs  </span><br><span class="line">---zookeeper----</span><br></pre></td></tr></table></figure>
<p>#指定 zk 集群地址，第四块要改的</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">zookeeper.connect=node1:2181,node2:2181,node3:2181</span><br></pre></td></tr></table></figure>
<p><img src="/../kafkaimg/2.png"><br><img src="/../kafkaimg/3.png"><br><img src="/../kafkaimg/4.png"><br>3.	将配置好的kafka分发至其他两台虚拟机：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">scp -r /export/server/kafka root@node2:/export/server/</span><br><span class="line">scp -r /export/server/kafka root@node3:/export/server/</span><br></pre></td></tr></table></figure>
<ol start="4">
<li>   添加Kafka路径至环境变量profile文件中：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vi /etc/profile </span><br><span class="line">export KAFKA_HOME=/export/server/kafka </span><br><span class="line">export PATH=$PATH:$KAFKA_HOME/bin </span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></li>
</ol>
<p>#注意此操作在node2、node3上也需完成<br><img src="/../kafkaimg/5.png"><br>5.	在node2、node3上修改server.propertie中的brokeer编号：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vim /export/server/kafka/config/server.propertie</span><br><span class="line">broker.id=1 </span><br><span class="line">broker.id=2</span><br></pre></td></tr></table></figure>
<p>#(broker.id 不能重复)<br>6.	创建Kafka一键启动停止脚本方便启动：<br>#在&#x2F;export&#x2F;shell路径下创建kfkall.sh脚本，添加以下代码，并测试：<br>#kafka一键启停脚本</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">if [ $# -eq 0 ]</span><br><span class="line">then</span><br><span class="line">echo &quot;please input param:start stop&quot;</span><br><span class="line">else</span><br><span class="line"></span><br><span class="line">if [ $1 = start  ]</span><br><span class="line">then</span><br><span class="line">for i in &#123;1..3&#125;</span><br><span class="line">do</span><br><span class="line">echo &quot;$&#123;1&#125;ing node$&#123;i&#125;&quot;</span><br><span class="line">ssh node$&#123;i&#125; &quot;source /etc/profile;/export/server/kafka/bin/kafka-server-start.sh -daemon /export/server/kafka/config/server.properties&quot;</span><br><span class="line">done</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">if [ $1 = stop ]</span><br><span class="line">then</span><br><span class="line">for i in &#123;1..3&#125;</span><br><span class="line">do</span><br><span class="line">ssh node$&#123;i&#125; &quot;source /etc/profile;/export/server/kafka/bin/kafka-server-stop.sh&quot;</span><br><span class="line">done</span><br><span class="line">fi</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>
<p>#启动命令：kfkall.sh start<br><img src="/../kafkaimg/6.png"></p>
<h2 id="4-2Kafka基本命令行操作介绍"><a href="#4-2Kafka基本命令行操作介绍" class="headerlink" title="4.2Kafka基本命令行操作介绍"></a>4.2Kafka基本命令行操作介绍</h2><h3 id="1-创建topic（Kafka中所有的消息都是保存在主题中，要生产消息到Kafka，首先必须要有一个确定的主题）"><a href="#1-创建topic（Kafka中所有的消息都是保存在主题中，要生产消息到Kafka，首先必须要有一个确定的主题）" class="headerlink" title="1.创建topic（Kafka中所有的消息都是保存在主题中，要生产消息到Kafka，首先必须要有一个确定的主题）"></a>1.创建topic（Kafka中所有的消息都是保存在主题中，要生产消息到Kafka，首先必须要有一个确定的主题）</h3><p>#基本方式</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./kafka-topics.sh --create --topic tpc_1 --partitions 2 --replication-factor 2 --zookeeper node1:2181</span><br><span class="line"></span><br><span class="line">--replication-factor 副本数量</span><br><span class="line">--partitions 分区数量</span><br><span class="line">--topic topic 名称</span><br></pre></td></tr></table></figure>
<p>#手动指定副本的存储位置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --topic tpc_1 --zookeeper node1:2181 --replica-assignment 0:1,1:2</span><br></pre></td></tr></table></figure>
<p>该方式下,命令会自动判断所要创建的 topic 的分区数及副本数</p>
<p>#bootstrap方式<br>#创建名为test的主题</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --bootstrap-server node1:9092 --topic test</span><br></pre></td></tr></table></figure>
<p>#查看目前Kafka中的主题</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bin/kafka-topics.sh --list --bootstrap-server node1:9092</span><br></pre></td></tr></table></figure>
<h3 id="2-删除topic"><a href="#2-删除topic" class="headerlink" title="2.删除topic"></a>2.删除topic</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bin/kafka-topics.sh  --delete --topic tpc_1 --zookeeper node1：2181</span><br></pre></td></tr></table></figure>
<p>#（异步线程去删除）删除 topic,需要一个参数处于启用状态: delete.topic.enable &#x3D; true,否则删不掉</p>
<p>#使用 kafka-topics.sh 脚本删除主题的行为本质上只是在 ZooKeeper 中的 &#x2F;admin&#x2F;delete_topics 路径下 建一个与待删除主题同名的节点,以标记该主题为待删除的状态。与创建主题相同的是,真正删除主题的动作也是由 Kafka 的控制器负责完成的。</p>
<p>#如果想要快捷的彻底删除topic可利用第三方工具Kafa Tool进行操作<br>#在后边后进行讲解</p>
<h3 id="3-查看topic"><a href="#3-查看topic" class="headerlink" title="3.查看topic"></a>3.查看topic</h3><p>#(1)列出当前系统中的所有 topic </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bin/kafka-topics.sh --zookeeper node1:2181,node2:2181,node3:2181 --list</span><br></pre></td></tr></table></figure>
<p><img src="/../kafkaimg/7.png"><br>#(2)查看 topic 详细信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --topic tpc_1   --zookeeper node1:2181 --replica-assignment 0:1,1:2</span><br><span class="line">bin/kafka-topics.sh --describe --topic tpc_1 --zookeper node1:2181</span><br></pre></td></tr></table></figure>
<p><img src="/../kafkaimg/8.png"></p>
<h3 id="4-增加分区数"><a href="#4-增加分区数" class="headerlink" title="4.增加分区数"></a>4.增加分区数</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bin/kafka-topics.sh --alter --topic tpc_1 --partitions 3 --zookeeper node1:2181</span><br></pre></td></tr></table></figure>
<h3 id="5-动态配置topic参数"><a href="#5-动态配置topic参数" class="headerlink" title="5.动态配置topic参数"></a>5.动态配置topic参数</h3><p>#通过管理命令,可以为已创建的 topic 增加、修改、删除 topic level 参数</p>
<p>#添加、修改配置参数(开启压缩发送传输种提高kafka消息吞吐量的有效办法(‘gzip’, ‘snappy’, ‘lz4’, ‘zstd’))</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bin/kafka-configs.sh --zookeeper node1:2181 --entity-type topics --entity-name tpc_1 --alter --add-config compression.type=gzip </span><br></pre></td></tr></table></figure>
<p>#删除配置参数</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bin/kafka-configs.sh --zookeeper node1:2181 --entity-type topics --entity-name tpc_1 --alter --delete-config compression.type</span><br></pre></td></tr></table></figure>
<p><img src="/../kafkaimg/9.png"></p>
<h3 id="6-生产消息到Kakfa并进行消费"><a href="#6-生产消息到Kakfa并进行消费" class="headerlink" title="6.生产消息到Kakfa并进行消费"></a>6.生产消息到Kakfa并进行消费</h3><p>使用Kafka内置的测试程序，生产一些消息到Kafka的tpc_1主题中：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#example1-kafka-console-producer</span><br><span class="line">bin/kafka-console-producer.sh --broker-list node1:9092, node2:9092, node3:9092 --topic tpc_1</span><br></pre></td></tr></table></figure>
<p>输入信息：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;hello word </span><br><span class="line">&gt;kafka </span><br><span class="line">&gt;nihao</span><br></pre></td></tr></table></figure>
<p>复制node1会话，启动消费者监听生成信息：<br>#example2-kafka-console-consumer<br>#(1)消费消息(从头开始)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --bootstrap-server node1:9092, node2:9092, node1:9092 --topic tpc_1 --from-beginning</span><br></pre></td></tr></table></figure>
<p>#(2)指定要消费的分区,和要消费的起始 offset </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --bootstrap-server node1:9092,node2:9092,node3:9092 --topic tcp_1 --offset 2 --partition 0</span><br></pre></td></tr></table></figure>
<p><img src="/../kafkaimg/10.png"></p>
<h3 id="7-Kafka的生产者-x2F-消费者-x2F-工具"><a href="#7-Kafka的生产者-x2F-消费者-x2F-工具" class="headerlink" title="7.Kafka的生产者&#x2F;消费者&#x2F;工具"></a>7.Kafka的生产者&#x2F;消费者&#x2F;工具</h3><p>这里介绍的是Kafka Tool：</p>
<ul>
<li>浏览Kafka集群节点、多少个topic、多少个分区</li>
<li>创建topic&#x2F;删除topic</li>
<li>浏览ZooKeeper中的数据</li>
</ul>
<p>#填写基本配置（名称、hots地址、端口号）</p>
<p><img src="/../kafkaimg/11.png"><br>#测试连接<br><img src="/../kafkaimg/12.png"><br>#在这里可以对Kakfa中的分区、主题、brokers进行方便的图形化管理：<br><img src="/../kafkaimg/13.png"></p>
<h3 id="8-Kafka的基准测试"><a href="#8-Kafka的基准测试" class="headerlink" title="8.Kafka的基准测试"></a>8.Kafka的基准测试</h3><p>benchmark testing）是一种测量和评估软件性能指标的活动。我们可以通过基准测试，了解到软件、硬件的性能水平。主要测试负载的执行时间、传输速度、吞吐量、资源占用率等。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kafka-producer-perf-test.sh --topic tpc_1 --num-records 100000 --record-size 1024 --throughput -1 --producer-props bootstrap.servers=node1:9092 acks=1</span><br><span class="line">kafka-producer-perf-test.sh --topic tpc_7 --num-records 100000 --record-size 1024 --throughput -1 --producer-props bootstrap.servers=node1:9092 acks=1</span><br></pre></td></tr></table></figure>
<p><img src="/../kafkaimg/14.png"><br>#通过对比测试知道越是后面的主题，传输的速度更快</p>
<h2 id="4-3Kafka-Java-API开发"><a href="#4-3Kafka-Java-API开发" class="headerlink" title="4.3Kafka Java API开发"></a>4.3Kafka Java API开发</h2><h3 id="1-生产者api示例"><a href="#1-生产者api示例" class="headerlink" title="1.生产者api示例"></a>1.生产者api示例</h3><p>（1）	配置生产者客户端参数<br>（2）	创建相应的生产者实例<br>（3）	构建待发送的消息<br>（4）	发送消息<br>（5）	关闭生产者实例</p>
<h3 id="2-引入Maven依赖"><a href="#2-引入Maven依赖" class="headerlink" title="2.引入Maven依赖"></a>2.引入Maven依赖</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt; </span><br><span class="line">	&lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; </span><br><span class="line">	&lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; </span><br><span class="line">	&lt;version&gt;2.0.0&lt;/version&gt; </span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>
<h3 id="3-必要的参数配置"><a href="#3-必要的参数配置" class="headerlink" title="3.必要的参数配置"></a>3.必要的参数配置</h3><p>&#x2F;&#x2F;在创建真正的生产者实例前需要配置相应的参数,比如需要连接的 Kafka 集群地址。在 Kafka 生产者客户端 KatkaProducer 中有 3 个参数是必填的。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-bootstrap.servers </span><br><span class="line">-key.serializer </span><br><span class="line">-value.serializer</span><br></pre></td></tr></table></figure>
<h3 id="4-发送消息"><a href="#4-发送消息" class="headerlink" title="4.发送消息"></a>4.发送消息</h3><p>创建生产者实例和构建消息之后就可以开始发送消息了。发送消息主要有3 种模式：<br>（1）.发后即忘（fire-and-forget）<br>在大多数情况下,这种发送方式没有问题;<br>不过在某些时候(比如发生不可重试异常时)会造成消息的丢失。<br>这种发送方式的性能最高,可靠性最差。</p>
<p>ack–&gt;作用在broker<br>Future<RecordMetadata> send &#x3D; producer.send(rcd);-》也是异步</p>
<p>没成功的话，producer也不管了<br>（2）同步发送<br>try {<br>    producer.send(rcd).get( ); &#x2F;&#x2F;–》一旦调用get方法，就会阻塞<br>} catch (Exception e) {<br>    e.printStackTrace( );<br> }<br>0.8.x 前,有一个参数 <code>producer.type=sycn|asycn</code> 来决定生产者的发送模式;#-&gt;取消了</p>
<p>现已失效(其实，新版中,producer 在底层只有异步方式，若想同步，发送一次，get一次就可实现)</p>
<p>Future  future &#x3D; Callable.run( ) #-&gt; 有返回值，future.get（）<br>runnable.run（）#-&gt;无返回值<br>多线程，new thread，然后new一个runnable#-&gt;线程干活去了-&gt;没有返回值（拿不到）<br>Future future &#x3D;  Callable.run()#-&gt; future.get()-&gt;可以有同步的实现方式了-&gt;使用.get()方法，就可以实现同步了<br>（3）异步发送<br>回调函数会在 producer 收到 ack 时调用,为异步调用,该方法有两个参数,分别是 <code>RecordMetadata</code> 和<code>Exception</code>,如果 <code>Exception 为 null</code>,说明消息<code>发送成功</code>,如果 <code>Exception 不为 null</code>,说明消息<code>发送失败</code>。同时，则recordMetadata是有值的</p>
<p>#注意:消息发送失败会自动重试,不需要我们在回调函数中手动重试。</p>
<h3 id="5-生产者原理解析"><a href="#5-生产者原理解析" class="headerlink" title="5.生产者原理解析"></a>5.生产者原理解析</h3><p>1.一个生产者客户端由两个线程协调运行,这两个线程分别为<code>主线程</code>和 &#96;Sender 线程 。</p>
<p>2.在主线程中由<code>kafkaProducer</code>创建消息,然后通过可能的<code>拦截器</code>、<code>序列化器</code>和<code>分区器</code>的作用之后缓存到消息累加器(<code>RecordAccumulator</code>, 也称为消息收集器)中。</p>
<p>3.<code>Sender线程</code>负责从 <code>RecordAccumulator</code> 获取消息并将其发送到 Kafka 中; </p>
<p>4.<code>RecordAccumulator </code>主要用来<code>缓存消息</code>以便 Sender 线程可以批量发送, 进而减少网络传输的资源消耗以提升性能。 </p>
<p>5.<code>RecordAccumulator </code>缓存的大小可以通过生产者客户端参数 <code>buffer.memory</code> 配置, 默认值为 33554432B ,即 32M。<br>如果<code>生产者发送消息的速度超过发送到服务器的速度</code>,则会导致生产者空间不足,这个时候 <code>KafkaProducer.send()</code>方法调用要么被阻塞,要么抛出异常,这个取决于参数<code>max.block.ms</code> 的配置,此参数的默认值为 60000,即 60 秒。</p>
<p>6.主线程中发送过来的消息都会被迫加到 <code>RecordAccumulator </code>的某个<code>双端队列( Deque )</code>中, <code>RecordAccumulator </code>内部为每个分区都维护了一个双端队列,即 <code>Deque&lt;ProducerBatch&gt;``。 消息写入缓存时,</code>追加到双端队列的尾部&#96;;</p>
<p>7.<code>Sender </code>读取消息时,<code>从双端队列的头部读取</code>。</p>
<p>8.注意:<code>ProducerBatch </code>是指一个消息批次;<br>与此同时,会将较小的 <code>ProducerBatch </code>凑成一个较大 <code>ProducerBatch</code> ,也可以减少网络请求的次数以提升整体的吞吐量。</p>
<p>#问题：什么情况下，消息累加器中的分区会增多？<br>9.<code>ProducerBatch</code> 大小和 <code>batch.size</code> 参数也有着密切的关系。</p>
<p>10.当一条消息(<code>ProducerRecord </code>) 流入<code>RecordAccumulator</code> 时,会先寻找与消息分区所对应的双端队列(如果没有则新建),再从这个双端队列的尾部获取一个 <code>ProducerBatch</code> (如果没有则新建),查看 <code>ProducerBatch</code> 中是否还可以写入这个 <code>ProducerRecord</code>,如果可以写入,如果不可以则需要创建一个新的 <code>Producer Batch</code>。</p>
<p>11.在新建<code>ProducerBatch </code>时评估这条消息的大小是否超过 <code>batch.size</code> 参数大小, 如果不超过, 那么就以 <code>batch.size</code> 参数的大小来创建 <code>ProducerBatch</code>。</p>
<p>#如果生产者客户端需要向很多分区发送消息, 则可以将 buffer.memory 参数适当调大以增加整体的吞吐量。</p>
<p>12.<code>Sender </code>从 <code>RecordAccumulator</code> 获取缓存的消息之后,会进一步将<code>&lt;分区,Deque&lt;Producer Batch&gt;&gt;</code>的形式转变成<code>&lt;Node,List&lt; ProducerBatch&gt;</code>的形式,其中 Node 表示 Kafka 集群 broker 节点。</p>
<p>13.对于网络连接来说,生产者客户端是与具体 <code>broker</code> 节点建立的连接,也就是向具体的<code>broker</code>节点发送消息,而并不关心消息属于哪一个分区;</p>
<p>14.而对于 <code>KafkaProducer </code>的应用逻辑而言,我们只关注向哪个分区中发送哪些消息,所以在这里需要做一个应用逻辑层面到网络 I&#x2F;O 层面的转换。</p>
<p>15.在转换成<code>&lt;Node, List&lt;ProducerBatch&gt;&gt;</code>的形式之后, Sender 会进一步封装成<code>&lt;Node,Request&gt; </code>的形式, 这样就可以将 <code>Request </code>请求发往各个 Node 了,这里的 <code>Request </code>是 Kafka 各种协议请求;</p>
<p>16.请求在从 sender 线程发往 Kafka 之前还会保存到 <code>InFlightRequests </code>中,<code>InFlightRequests</code> 保存对象的具体形式为 <code>Map&lt;Nodeld, Deque&lt;request&gt;&gt;</code>,它的主要作用是缓存了已经发出去但还没有收到服务端响应的请求(Nodeld 是一个 String 类型,表示节点的 id 编号)。</p>
<p>17.与此同时,<code>InFlightRequests</code> 还提供了许多管理类的方法,并且通过配置参数还可以限制每个连接(也就是客户端与 Node 之间的连接) 最多缓存的请求数。</p>
<p>18.这个配置参数为 <code>max.in.flight.request.per.connection</code> ,默认值为 5,即每个连接最多只能缓存 5 个未响应的请求,超过该数值之后就不能再向这个连接发送更多的请求了,除非有缓存的请求收到了响应( Response )。</p>
<p>19.通过比较 <code>Deque&lt;Request&gt;</code> 的 <code>size</code> 与这个<code>参数的大小</code>来判断对应的 Node 中是否己经堆积了很多未响应的消息, 如果真是如此, 那么<code>说明这个 Node 节点负载较大或网络连接有问题,再继其发送请求会增大请求超时的可能</code>。</p>
<h3 id="6-重要的生产者参数"><a href="#6-重要的生产者参数" class="headerlink" title="6.重要的生产者参数"></a>6.重要的生产者参数</h3><p>（1）	Acks<br><img src="/../kafkaimg/15.png"><br>（2）	max.request.size<br>（3）	commpression.type<br>（4）	retries和retry.backoff.ms<br>（5）	batch.size<br>（6）	linger.ms（和batchsize有联系）<br>（7）	enable.idempotence -&gt;true&#x2F;false<br>（8）	partitioner.classes<br>4.4在idea上生产消息<br>1.开启kafka,zookeeper，<br>（1）配置生产者参数<br>Properties props &#x3D; new Properties();<br>两种配置方法<br>配置方式1–&gt;比较容易会将参数的名称写错<br>&#x2F;&#x2F;        props.load(ProducerDemo.class.getClassLoader().getResourceAsStream(“client.properties”));<br>&#x2F;&#x2F;        props.put(“bootstarp.servers”,”node1:9092,node2:9092,node3:9092”);</p>
<p>配置方式2，利用常量类，去进行配置，不容易写错参数名，比较容易记忆</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,SERVERS);</span><br><span class="line">        props.put(ProducerConfig.ACKS_CONFIG,&quot;all&quot;);</span><br><span class="line">        props.put(ProducerConfig.RETRIES_CONFIG,3);</span><br><span class="line">        props.put(ProducerConfig.BATCH_SIZE_CONFIG,10);</span><br><span class="line">//        props.put(ProducerConfig.LINGER_MS_CONFIG,10000);</span><br><span class="line">//        props.put(ProducerConfig.MAX_REQUEST_SIZE_CONFIG,10);</span><br><span class="line">//        props.put(ProducerConfig.BUFFER_MEMORY_CONFIG,1024);</span><br><span class="line">        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br></pre></td></tr></table></figure>
<p>（2）创建生产者实例<br>KafkaProducer&lt;String,String&gt; producer &#x3D;  new KafkaProducer&lt;&gt;(props);<br>（3）构建待发送消息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for(int i = 0;i&lt;100;i++) &#123;</span><br><span class="line">    ProducerRecord&lt;String, String&gt; msg = new ProducerRecord&lt;&gt;(&quot;tpc_1&quot;, &quot;name&quot;+i, &quot;0526bigdata2001-wwl+&quot; +RandomStringUtils.randomAlphabetic(4,7) );</span><br></pre></td></tr></table></figure>
<p>（4）发送消息<br>（5）关闭生产者实例</p>
<h3 id="2-服务器上接收消息"><a href="#2-服务器上接收消息" class="headerlink" title="2.服务器上接收消息"></a>2.服务器上接收消息</h3><p>进入kafka安装目录下<br>执行</p>
<pre><code>bin/kafka-console-consumer.sh --bootstrap-server node1:9092, node2:9092, node1:9092 --topic tpc_1 --from-beginning
</code></pre>
<h3 id="3-Idea执行代码"><a href="#3-Idea执行代码" class="headerlink" title="3.Idea执行代码"></a>3.Idea执行代码</h3><p><img src="/../kafkaimg/16.png"></p>
<h3 id="4-查看接收到的消息"><a href="#4-查看接收到的消息" class="headerlink" title="4.查看接收到的消息"></a>4.查看接收到的消息</h3><p><img src="/../kafkaimg/17.png"></p>
]]></content>
  </entry>
  <entry>
    <title>Spark Standalone环境部署</title>
    <url>/2023/05/31/spark-standalone/</url>
    <content><![CDATA[<h1 id="Spark-Standalone"><a href="#Spark-Standalone" class="headerlink" title="Spark-Standalone"></a>Spark-Standalone</h1><h2 id="一-安装Anaconda"><a href="#一-安装Anaconda" class="headerlink" title="一.安装Anaconda"></a>一.安装Anaconda</h2><p>上传Anaconda3-2021.05-Linux-x86_64.sh文件到Linux服务器上</p>
<p><img src="/../image-standalone/1.jpg" alt="图 1">  </p>
<p>安装</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sh ./Anaconda3-2021.05-Linux-x86_64.sh</span><br></pre></td></tr></table></figure>
<p><img src="/../image-standalone/2.jpg" alt="图 2">  </p>
<p><img src="/../image-standalone/3.jpg" alt="图 3"> </p>
<p><img src="/../image-standalone/4.jpg" alt="图 4">  </p>
<p>重新进入到finalshell后查看</p>
<p><img src="/../image-standalone/5.jpg" alt="图 5">  </p>
<p>此时base表示已经安装完成</p>
<h2 id="二-所有机器配置环境变量"><a href="#二-所有机器配置环境变量" class="headerlink" title="二.所有机器配置环境变量"></a>二.所有机器配置环境变量</h2><p>上传spark.jar包并解压</p>
<p><img src="/../image-standalone/6.jpg" alt="图 6">  </p>
<p><img src="/../image-standalone/7.jpg" alt="图 7">  </p>
<h3 id="配置环境文件"><a href="#配置环境文件" class="headerlink" title="配置环境文件"></a>配置环境文件</h3><h5 id="配置workers文件"><a href="#配置workers文件" class="headerlink" title="配置workers文件"></a>配置workers文件</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 改名，将workers.template改名成workers</span><br><span class="line"></span><br><span class="line"># 进入到workers里编辑文件</span><br></pre></td></tr></table></figure>
<p><img src="/../image-standalone/9.jpg" alt="图 9">  </p>
<p><img src="/../image-standalone/10.jpg" alt="图 10">  </p>
<h5 id="配置spark-env-sh文件"><a href="#配置spark-env-sh文件" class="headerlink" title="配置spark-env.sh文件"></a>配置spark-env.sh文件</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 1.改名，将spark-env.sh.template改名成为将spark-env.sh</span><br><span class="line"></span><br><span class="line"># 2.编辑saprk-env.sh,添加以下内容</span><br><span class="line"></span><br><span class="line">## 设置JAVA安装目录</span><br><span class="line">JAVA_HOME=/export/server/jdk</span><br><span class="line"></span><br><span class="line">## HADOOP软件配置文件目录，读取HDFS上文件和运行YARN集群</span><br><span class="line">HADOOP_CONF_DIR=/export/server/hadoop/etc/hadoop</span><br><span class="line">YARN_CONF_DIR=/export/server/hadoop/etc/hadoop</span><br><span class="line"></span><br><span class="line">## 指定spark老大Master的IP和提交任务的通信端口</span><br><span class="line"># 告知Spark的master运行在哪个机器上</span><br><span class="line">export SPARK_MASTER_HOST=node1</span><br><span class="line"># 告知sparkmaster的通讯端口</span><br><span class="line">export SPARK_MASTER_PORT=7077</span><br><span class="line"># 告知spark master的 webui端口</span><br><span class="line">SPARK_MASTER_WEBUI_PORT=8080</span><br><span class="line"></span><br><span class="line"># worker cpu可用核数</span><br><span class="line">SPARK_WORKER_CORES=1</span><br><span class="line"># worker可用内存</span><br><span class="line">SPARK_WORKER_MEMORY=1g</span><br><span class="line"># worker的工作通讯地址</span><br><span class="line">SPARK_WORKER_PORT=7078</span><br><span class="line"># worker的 webui地址</span><br><span class="line">SPARK_WORKER_WEBUI_PORT=8081</span><br><span class="line"></span><br><span class="line">## 设置历史服务器</span><br><span class="line"># 配置的意思是  将spark程序运行的历史日志 存到hdfs的/sparklog文件夹中</span><br><span class="line">SPARK_HISTORY_OPTS=&quot;-Dspark.history.fs.logDirectory=hdfs://node1:8020/sparklog/ -Dspark.history.fs.cleaner.enabled=true&quot;</span><br></pre></td></tr></table></figure>
<p><img src="/../image-standalone/11.jpg" alt="图 11">  </p>
<p><img src="/../image-standalone/12.jpg" alt="图 12">  </p>
<h5 id="在HDFS上传件运行历史存放的文件夹"><a href="#在HDFS上传件运行历史存放的文件夹" class="headerlink" title="在HDFS上传件运行历史存放的文件夹"></a>在HDFS上传件运行历史存放的文件夹</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hadoop fs -mkdir /sparklog</span><br><span class="line">hadoop fs -chmod 777 /sparklog</span><br></pre></td></tr></table></figure>
<p><img src="/../image-standalone/13.jpg" alt="图 13">  </p>
<h5 id="配置spark-defaults-conf文件"><a href="#配置spark-defaults-conf文件" class="headerlink" title="配置spark-defaults.conf文件"></a>配置spark-defaults.conf文件</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 1. 改名</span><br><span class="line">mv spark-defaults.conf.template spark-defaults.conf</span><br><span class="line"></span><br><span class="line"># 2. 修改内容, 添加下内容</span><br><span class="line"></span><br><span class="line"># 开启spark的日期记录功能</span><br><span class="line">spark.eventLog.enabled 	true</span><br><span class="line"># 设置spark日志记录的路径</span><br><span class="line">spark.eventLog.dir	 hdfs://node1:8020/sparklog/ </span><br><span class="line"># 设置spark日志是否启动压缩</span><br><span class="line">spark.eventLog.compress 	true</span><br></pre></td></tr></table></figure>
<p><img src="/../image-standalone/14.jpg" alt="图 14">  </p>
<p><img src="/../image-standalone/15.jpg" alt="图 15">  </p>
<h5 id="配置log4j-properties-文件"><a href="#配置log4j-properties-文件" class="headerlink" title="配置log4j.properties 文件"></a>配置log4j.properties 文件</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 1. 改名</span><br><span class="line">mv log4j.properties.template log4j.properties</span><br><span class="line"></span><br><span class="line"># 2.编辑log4j.properties，</span><br><span class="line">修改内容如下图所示</span><br></pre></td></tr></table></figure>
<p><img src="/../image-standalone/16.jpg" alt="图 16">  </p>
<p><img src="/../image-standalone/17.jpg" alt="图 17">  </p>
<h3 id="将spark安装文件分发到node2，node3上"><a href="#将spark安装文件分发到node2，node3上" class="headerlink" title="将spark安装文件分发到node2，node3上"></a>将spark安装文件分发到node2，node3上</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">scp -r spark-3.1.2-bin-hadoop3.2 node2:/export/server/</span><br><span class="line">scp -r spark-3.1.2-bin-hadoop3.2 node3:/export/server/</span><br></pre></td></tr></table></figure>
<p>node2<br><img src="/../image-standalone/18.jpg" alt="图 18">  </p>
<p>node3<br><img src="/../image-standalone/19.jpg" alt="图 19">  </p>
<p>同时，在node2和node3上给spark安装目录添加软连接</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ln -s /export/server/spark-3.1.2-bin-hadoop3.2 /export/server/spark</span><br></pre></td></tr></table></figure>
<p>node2<br><img src="/../image-standalone/20.jpg" alt="图 20">  </p>
<p>node3<br><img src="/../image-standalone/21.jpg" alt="图 21">  </p>
<h3 id="检查环境变量"><a href="#检查环境变量" class="headerlink" title="检查环境变量"></a>检查环境变量</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">进入到profile里</span><br><span class="line">检查</span><br><span class="line">JAVA_HOME</span><br><span class="line">SPARK_HOME</span><br><span class="line">PYSPARK_PYTHON</span><br><span class="line">等环境变量是否正确指向正确的目录</span><br></pre></td></tr></table></figure>
<p><img src="/../image-standalone/22.jpg" alt="图 22">  </p>
<p><img src="/../image-standalone/23.jpg" alt="图 23">  </p>
<p><img src="/../image-standalone/24.jpg" alt="图 24">  </p>
<h3 id="启动历史服务器"><a href="#启动历史服务器" class="headerlink" title="启动历史服务器"></a>启动历史服务器</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sbin/start-history-server.sh</span><br></pre></td></tr></table></figure>
<p><img src="/../image-standalone/25.jpg" alt="图 25">  </p>
<h3 id="启动Spark的Master和Worker进程"><a href="#启动Spark的Master和Worker进程" class="headerlink" title="启动Spark的Master和Worker进程"></a>启动Spark的Master和Worker进程</h3><p><img src="/../image-standalone/26.jpg" alt="图 26">  </p>
<h3 id="查看Master的WEB-UI"><a href="#查看Master的WEB-UI" class="headerlink" title="查看Master的WEB UI"></a>查看Master的WEB UI</h3><p>默认窗口设置的是8080</p>
<p><img src="/../image-standalone/28.jpg" alt="图 28">  </p>
<h2 id="连接到Standalone集群"><a href="#连接到Standalone集群" class="headerlink" title="连接到Standalone集群"></a>连接到Standalone集群</h2><h5 id="bin-x2F-pyspark"><a href="#bin-x2F-pyspark" class="headerlink" title="bin&#x2F;pyspark"></a>bin&#x2F;pyspark</h5><p>执行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bin/pyspark --master spark://node1:7077</span><br></pre></td></tr></table></figure>
<p><img src="/../image-standalone/29.jpg" alt="图 29">  </p>
<h5 id="bin-x2F-spark-shell"><a href="#bin-x2F-spark-shell" class="headerlink" title="bin&#x2F;spark-shell"></a>bin&#x2F;spark-shell</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bin/spark-shell --master spark://node1:7077</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//测试代码</span><br><span class="line">sc.parallelize(Array(1,2,3,4,5)).map(x=&gt; x + 1).collect()</span><br></pre></td></tr></table></figure>
<p><img src="/../image-standalone/30.jpg" alt="图 30">  </p>
<h5 id="bin-x2F-spark-submit-PI"><a href="#bin-x2F-spark-submit-PI" class="headerlink" title="bin&#x2F;spark-submit(PI)"></a>bin&#x2F;spark-submit(PI)</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bin/spark-submit --master spark://node1:7077 /export/server/spark/examples/src/main/python/pi.py 100</span><br></pre></td></tr></table></figure>
<p><img src="/../image-standalone/31.jpg" alt="图 31">  </p>
<h3 id="查看历史服务器"><a href="#查看历史服务器" class="headerlink" title="查看历史服务器"></a>查看历史服务器</h3><p>历史服务器的默认端口是: 18080</p>
<p><img src="/../image-standalone/32.jpg" alt="图 32">  </p>
<h2 id="3-总结"><a href="#3-总结" class="headerlink" title="3.总结"></a>3.总结</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">这个spark-standalone部署的任务总体来说还是很简单的，</span><br><span class="line">从头到尾基本没有遇到什么问题，基本上很顺利的就结束了这个任务点。</span><br><span class="line">也就在连接到standalone集群时出现了拒绝连接的情况，</span><br><span class="line">结果发现是hdf集群和yarn集群没有启动，除此之外就没有什么问题了</span><br></pre></td></tr></table></figure>]]></content>
  </entry>
  <entry>
    <title>docker 部署</title>
    <url>/2023/06/07/spark-docker/</url>
    <content><![CDATA[<h1 id="docker配置"><a href="#docker配置" class="headerlink" title="docker配置"></a>docker配置</h1><h3 id="1-初始化环境"><a href="#1-初始化环境" class="headerlink" title="1.初始化环境"></a>1.初始化环境</h3><ol>
<li>   在安装docker之前，先初始化机器环境，如果之前安装过旧版本的docker，应该先使用命令进行卸载。（我这里之前没有安装过旧版本的docker，就不进行写在操作了）</li>
</ol>
<h3 id="2-进行yum源配置。"><a href="#2-进行yum源配置。" class="headerlink" title="2.进行yum源配置。"></a>2.进行yum源配置。</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mv/etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup</span><br><span class="line"></span><br><span class="line">wget-O/etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</span><br><span class="line">wget-O/etc/yum.repos.d/epel.repo</span><br><span class="line">   http://mirrors.aliyun.com/repo/epel-7.repo</span><br><span class="line">yum clean all</span><br><span class="line">yum makecache</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/1.jpg" alt="图 1"></p>
<h3 id="3-安装docker，首先需要虚拟机联网，安装yum工具"><a href="#3-安装docker，首先需要虚拟机联网，安装yum工具" class="headerlink" title="3.安装docker，首先需要虚拟机联网，安装yum工具"></a>3.安装docker，首先需要虚拟机联网，安装yum工具</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum install -y yum-utils \</span><br><span class="line">           device-mapper-persistent-data \</span><br><span class="line">lvm2--skip-broken</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/2.jpg" alt="图 2"></p>
<h3 id="4-配置网卡转发。"><a href="#4-配置网卡转发。" class="headerlink" title="4.配置网卡转发。"></a>4.配置网卡转发。</h3><p>1.docker必须安装在centos7平台，内核版本不低于3.10在centos平台运行docker可能会遇见些告警信息，修改内核配置参数，打开内核转发功能</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#写入</span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/sysctl.d/docker.conf</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.ipv4.conf.default.rp_filter = 0</span><br><span class="line">net.ipv4.conf.all.rp_filter = 0</span><br><span class="line">net.ipv4.ip_forward=1</span><br><span class="line">EOF</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>2.重新加载内核参数</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">modprobe br_netfilter</span><br><span class="line">sysctl -p /etc/sysctl.d/docker.conf</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/3.jpg" alt="图 3"></p>
<h3 id="5-利用yum进行docker安装"><a href="#5-利用yum进行docker安装" class="headerlink" title="5.利用yum进行docker安装"></a>5.利用yum进行docker安装</h3><p>提前配置好yum仓库<br>1.阿里云自带仓库 2.阿里云提供的docker专属repo仓库</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">curl-o/etc/yum.repos.d/docker-ce.repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line">cur-o/etc/yum.repos.d/Centos-7.repo </span><br><span class="line">http://mirrors.aliyun.com/repo/Centos-7.repo</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/4.jpg" alt="图 4"><br>#更新yum缓存<br><img src="/../image-docker/5.jpg" alt="图 5"><br>#可以直接yum安装docker了<br>#查看源中可用版本</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum list docker-ce --showduplicates | sort -r</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/6.jpg" alt="图 6"><br>#yum安装</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum install docker-ce -y</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/7.jpg" alt="图 7"><br>##查看docker版本，验证是否验证成功</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker -v</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/8.jpg" alt="图 8"></p>
<h3 id="6-配置镜像加速器"><a href="#6-配置镜像加速器" class="headerlink" title="6.配置镜像加速器"></a>6.配置镜像加速器</h3><p>#用于加速镜像文件下载,选用阿里云镜像站</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/docker</span><br><span class="line">touch /etc/docker/daemon.json</span><br><span class="line">vim /etc/docker/daemon.json</span><br><span class="line">&#123;</span><br><span class="line">&quot;registry-mirrors&quot; : [</span><br><span class="line">&quot;https://8xpk5wnt.mirror.aliyuncs.com&quot;</span><br><span class="line">]</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/9.jpg" alt="图 9"></p>
<h3 id="6-启动docker"><a href="#6-启动docker" class="headerlink" title="6.启动docker"></a>6.启动docker</h3><p>启动docker前，一定要关闭防火墙后！！</p>
<p>关闭</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>禁止开机启动防火墙</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">systemctl disable firewalld</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/10.jpg" alt="图 10"><br><img src="/../image-docker/11.jpg" alt="图 11"><br><img src="/../image-docker/12.jpg" alt="图 12"><br>查看docker信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker info</span><br><span class="line">docker ps</span><br><span class="line">docker image-docker</span><br><span class="line">docker version</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/13.jpg" alt="图 13"><br><img src="/../image-docker/14.jpg" alt="图 14"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">## docker-client</span><br><span class="line">which docker</span><br><span class="line">## docker daemon</span><br><span class="line">ps aux |grep docker</span><br><span class="line">## containerd</span><br><span class="line">ps aux|grep containerd</span><br><span class="line">systemctl status containerd</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/15.jpg" alt="图 15"></p>
<h3 id="7-docker初体验"><a href="#7-docker初体验" class="headerlink" title="7.docker初体验"></a>7.docker初体验</h3><p>#1.查看本地的docker镜像有哪些</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker image ls 或 docker image-docker</span><br></pre></td></tr></table></figure>
<p>#2.可选择删除旧版本</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker rmi 镜像id</span><br></pre></td></tr></table></figure>
<p>#3.搜索一下远程仓库中的镜像文件是否存在</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker search nginx</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/16.jpg" alt="图 16"><br>#4.拉取，下载镜像</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docerk pull nginx</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/17.jpg" alt="图 17"><br>#5.再次查看镜像</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker image-docker</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/18.jpg" alt="图 18"><br>#6.运行镜像，运行出具体内容，在容器中就跑着一个nginx服务</p>
<p>docker run 参数 镜像的名字&#x2F;id</p>
<p>#-d 后台运行容器</p>
<p>#-p 80:80 端口映射，宿主机端口：容器内端口，访问宿主机的80端口，也就访问到容器中的80端口</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d -p 80:80 nginx</span><br></pre></td></tr></table></figure>
<p>#会返回一个容器的id</p>
<p>#7.查看容器是否在运行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker ps</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/19.jpg" alt="图 19"><br>#8.访问网站<br>192.168.88.163:80<br><img src="/../image-docker/20.jpg" alt="图 20"></p>
<h3 id="8-获取镜像"><a href="#8-获取镜像" class="headerlink" title="8.获取镜像"></a>8.获取镜像</h3><p>1.获取镜像，镜像托管仓库，好比yum源一样<br>默认的docker仓库是，dockerhub ，有大量的优质的镜像，以及用户自己上传的镜像 centos容器 vim nginx 。。提交为镜像，上传到dockehub</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker search centos</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/21.jpg" alt="图 21"><br>我们在获取redis镜像的时候，发现下载了多行信息，最终仅得到了一个完整的镜像文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@node3 ~]# docker pull redis</span><br><span class="line">[root@node3 ~]# docker image-docker</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/22.jpg" alt="图 22"><br><img src="/../image-docker/23.jpg" alt="图 23"><br>2.查看本地的镜像文件有哪些</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker image-docker </span><br><span class="line">docker image ls</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/24.jpg" alt="图 24"><br>3.下载docker镜像</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker pull centos # 默认的是 centos:latest</span><br><span class="line">docker pull centos:7.8.2003</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/25.jpg" alt="图 25"><br>4.查看docker镜像的存储路径</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker info |grep Root</span><br><span class="line">#Docker Root Dir: /var/lib/docker</span><br><span class="line">#具体位置</span><br><span class="line">ls /var/lib/docker/image/overlay2/imagedb/content/sha256</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/26.jpg" alt="图 26"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dockerimage-docker</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/27.jpg" alt="图 27"><br>5.该文件作用是</p>
<p>记录 镜像 和容器的配置关系</p>
<p>使用不同的镜像，生成容器# -it 开启一个交互式的终端–rm 容器退出时删除该容器</p>
<p>#再运行一个7.8centos<br><img src="/../image-docker/28.jpg" alt="图 28"><br>9.#1.查看所有镜像<br><img src="/../image-docker/29.jpg" alt="图 29"><br>#2.查看具体镜像<br><img src="/../image-docker/30.jpg" alt="图 30"><br>#3.指定tag查看<br><img src="/../image-docker/31.jpg" alt="图 31"><br>#4.只列出镜像id<br>-q –quiet 只列出id<br><img src="/../image-docker/32.jpg" alt="图 32"><br>#5.格式化显示镜像</p>
<p>这是docker的模板语言，–format</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker image-docker --format &quot;&#123;&#123;.ID&#125;&#125;--&#123;&#123;.Repository&#125;&#125;&quot;</span><br><span class="line">[root@node3 ~]# docker image-docker --format &quot;&#123;&#123;.ID&#125;&#125;--&#123;&#123;.Repository&#125;&#125;&quot;</span><br><span class="line">605c77e624dd--nginx</span><br><span class="line">7614ae9453d1--redis</span><br><span class="line">5d9483f9a7b2—mysql</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/33.jpg" alt="图 33"><br>2.运行容器，且进入容器内，且在容器内执行某个命令</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@node1 ~]# docker run -it centos:7.8.2003 sh</span><br><span class="line">sh-4.2#</span><br><span class="line">sh-4.2#</span><br><span class="line">sh-4.2# cat /etc/redhat-release</span><br><span class="line">Centos Linux release 7.8.2003 (Core)</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/34.jpg" alt="图 34"><br>3.开启一个容器，让它帮你运行某个程序，属于前台运行，会卡住一个终端</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@node1 ~]# docker run centos:7.8.2003 ping baidu.com</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/35.jpg" alt="图 35"><br>4.运行一个活着的容器，docker ps可以看到的容器</p>
<p>-d 参数，让容器在后台跑着 (针对宿主机而言)</p>
<p>返回容器id</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d centos:7.8.2003 ping baidu.com</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/36.jpg" alt="图 36"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># -d 后台运行</span><br><span class="line">docker run -d --rm --name pythonav centos:7.8.2003 pingpythonav.cn</span><br><span class="line"></span><br><span class="line">Dockerps</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/37.jpg" alt="图 37"><br><img src="/../image-docker/38.jpg" alt="图 38"><br>6.查看容器日志的玩法，刷新日志</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># docker logs -f 容器id</span><br><span class="line">docker logs -f f2598cb26363</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/39.jpg" alt="图 39"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#查看最后五条</span><br><span class="line">docker logs f2598cb26363 | tail -5</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/40.jpg" alt="图 40"><br>8.查看容器的详细信息，用于高级的调试</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker container inspect 容器id</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/41.jpg" alt="图 41"><br>9.容器的端口映射<br>后台运行nginx容器，且起个名字，且端口映射宿主机的80端口，访问到容器内的80端口</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d --name bigdata_nginx -p 85:80 nginx</span><br><span class="line">查看容器</span><br><span class="line">[root@yc_docker81 ~]# docker ps</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/42.jpg" alt="图 42"><br>#9.1查看容器的端口转发情况</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker port 容器id</span><br><span class="line">docker port 2e73fac44507</span><br><span class="line">80/tcp -&gt; 0.0.0.0:85</span><br><span class="line">80/tcp -&gt; :::85</span><br></pre></td></tr></table></figure>
<p>#9.2随机端口映射 -P 随机访问一个宿主机的空闲端口，映射到容器内打开的端口</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d --name bigdata_nginx_random -P nginx</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/43.jpg" alt="图 43"><br><img src="/../image-docker/44.jpg" alt="图 44"></p>
<h3 id="10-创建并运行nginx容器的命令："><a href="#10-创建并运行nginx容器的命令：" class="headerlink" title="10.创建并运行nginx容器的命令："></a>10.创建并运行nginx容器的命令：</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run --name containerName -p 80:80 -d nginx</span><br></pre></td></tr></table></figure>
<p>将name<br>修改为mn<br>进入容器。进入我们刚刚创建的nginx容器的命令为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker exec -it 25866bdfa0e3 bash    //it后面跟的是容器的id</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/45.jpg" alt="图 45"><br>修改index.html的内容<br>容器内没有vi命令，无法直接修改，我们用下面的命令来修改：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sed -i -e &#x27;s#Welcome to nginx#人工智能学院欢迎您#g&#x27; -e &#x27;s#&lt;head&gt;#&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;&gt;#g&#x27; index.html</span><br><span class="line">在浏览器访问自己的虚拟机地址，例如我的是：http://192.168.88.163</span><br></pre></td></tr></table></figure>
<p><img src="/../image-docker/46.jpg" alt="图 46"></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">（一）当我关闭防火墙，准备启动docker时出现了报错，具体报错信息是</span><br><span class="line">Job for docker.service failed because the control process exited with error cod</span><br><span class="line">See &quot;systemctl status docker.service&quot; and &quot;journalcti -xe&quot; for details.因为没遇到过，所以我去查了百度，发现是防火墙可能是关闭错误了，根据百度上给的解决方案我关闭了selinux,具体方法就是修改config里面的内容，保存并退出后，，报错便不再出现。</span><br><span class="line">(二) 在创建新容器的时候我发现输入容器的name不会百分百运行出来，于是我将容器的id替换掉name后，就可以运行了。</span><br><span class="line">经过以上配置过程，过程中也遇到错误，也有不理解的问题，最后都通过百度或者询问身边的同学解决，这给我在本课程学习中提高了信心和对于知识的掌握。</span><br></pre></td></tr></table></figure>



]]></content>
  </entry>
  <entry>
    <title>spark全流程配置SparkHA|SparkYarn</title>
    <url>/2023/06/07/spark%E5%85%A8%E6%B5%81%E7%A8%8B%E9%85%8D%E7%BD%AESparkHA-SparkYarn/</url>
    <content><![CDATA[<h1 id="一、在Spark-Standlone集群下"><a href="#一、在Spark-Standlone集群下" class="headerlink" title="一、在Spark Standlone集群下"></a>一、在Spark Standlone集群下</h1><p> Master可能会遇到无法阻止的问题。解决问题就需要用到备用的Master，也就是所谓的HA模式。</p>
<h2 id="基于Zookeeper实现HA"><a href="#基于Zookeeper实现HA" class="headerlink" title="基于Zookeeper实现HA"></a>基于Zookeeper实现HA</h2><p>前提：确保Zookeeper和HDFS均启动<br>（1）	进入&#x2F;export&#x2F;server&#x2F;spark&#x2F;conf目录下，修改spark-env.sh文件，删除SPARK_MASTER_HOST&#x3D;node1  ，因为这个配置说的是固定的master是谁了，不修改的话，就不能进行动态切换master。<br>这里把这段注释掉就行<br><img src="/../image/1.png"></p>
<p>（2）再在spark-env.sh中增加：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SPARK_DAEMON_JAVA_OPTS=&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=node1:2181,node2:2181,node3:2181 -Dspark.deploy.zookeeper.dir=/spark-ha&quot;</span><br></pre></td></tr></table></figure>
<p>#spark.deploy.recoveryMode 指定HA模式 基于Zookeeper实现<br>#指定Zookeeper的连接地址<br>#指定在Zookeeper中注册临时节点的路径<br>（3）将spark-env.sh 分发到每一台服务器上（这里我配置的是node1，所以发到node2和node3上，根据自己实际情况改变）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">scp spark-env.sh node2:/export/server/spark/conf/</span><br><span class="line">scp spark-env.sh node3:/export/server/spark/conf/</span><br></pre></td></tr></table></figure>
<p>到这里前置工作就做完了，注意别忘了启动HDFS和Zookeeper</p>
<h1 id="二：启动集群"><a href="#二：启动集群" class="headerlink" title="二：启动集群"></a>二：启动集群</h1><p>（1）：在node1上启动一个master和全部的worker<br>在spark的安装目录下执行sbin&#x2F;start-all.sh<br>Jps一下查看进程（演示node1）<br><img src="/../image/2.png"><br>然后再在node2上再启动一个备用的master进程<br>sbin&#x2F;start-master.sh<br>在node2上看一下进程，有master进程即可<br><img src="/../image/3.png"><br>（2）：到浏览器进入我们的8080端口（如果80端口被占用那就顺延到81端口）<br><img src="/../image/4.png"><br>此时代表80端口被占用了，所以就顺延到81端口<br><img src="/../image/5.png"><br>同时也能看到node1的master是活的<br>同理连接一下node2</p>
<p>（3）：提交一个spark任务到node1的master上</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bin/spark-submit --master spark://node1:7077 /export/server/spark/examples/src/main/python/pi.py 1000</span><br></pre></td></tr></table></figure>
<p>提交完以后新建一个node1的标签页，然后杀死node1上的master进程<br><img src="/../image/6.png"><br>然后回到原来标签页<br><img src="/../image/7.png"><br>因为node1的master被干掉了，但是这个进程没有因此结束，这时候node2的master进程就马上顶上去，代替了node1的master进行工作，最后得出结果。<br>然后我们去网页看看node1和node2<br><img src="/../image/8.png"><br><img src="/../image/9.png"><br>node1连接不上了，因为node1的master已经死了，然后node2的master从备用状态变成了活着，下面还有刚刚完成的进程，这就是我们的HA模式。</p>
<h1 id="Wordcount测试"><a href="#Wordcount测试" class="headerlink" title="Wordcount测试"></a>Wordcount测试</h1><p><img src="/../image/10.png"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">resultRDD = sc.textFile(&quot;hdfs://node1:8020/pydata/words.txt&quot;) \ </span><br><span class="line">.flatMap(lambda line: line.split(&quot; &quot;)) \ </span><br><span class="line">.map(lambda x: (x, 1)) \ .reduceByKey(lambda a, b: a + b) </span><br><span class="line">resultRDD .collect()</span><br></pre></td></tr></table></figure>
<p><img src="/../image/11.png"></p>
<h1 id="三：SparkOnYarn模式环境"><a href="#三：SparkOnYarn模式环境" class="headerlink" title="三：SparkOnYarn模式环境"></a>三：SparkOnYarn模式环境</h1><p>（1）：确保HADOOP_CONF_DIR或者YARN_CONF_DIR在spark-env.sh和环境变量中<br>如果没有，在&#x2F;etc&#x2F;profile环境变量中加入</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#HADOOP_CONF_DIR</span><br><span class="line">export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop</span><br></pre></td></tr></table></figure>
<p>别忘了重新加载环境变量source &#x2F;etc&#x2F;profile</p>
<p>在&#x2F;export&#x2F;server&#x2F;spark&#x2F;conf&#x2F;spark-env.sh中加入<br>##HADOOP软件配置文件目录，读取HDFS上文件和运行YARN集群</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">HADOOP_CONF_DIR=/export/server/hadoop/etc/hadoop</span><br><span class="line">YARN_CONF_DIR=/export/server/hadoop/etc/hadoop</span><br></pre></td></tr></table></figure>


<p>（2）连接到YARN中<br>bin&#x2F;pyspark –master yarn –deploy-mode client | cluster<br>#–deploy-mode 选项是指定部署模式, 默认是 客户端模式<br>#client就是客户端模式<br>#cluster就是集群模式<br>#–deploy-mode 仅可以用在YARN模式下</p>
<p>这里注意：交互式环境 pyspark  和 spark-shell  无法运行 cluster模式</p>
<p><img src="/../image/12.png"><br>测试运行圆周率：采用client模式</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SPARK_HOME=/export/server/spark </span><br><span class="line">$&#123;SPARK_HOME&#125;/bin/spark-submit \ </span><br><span class="line">--master yarn \ </span><br><span class="line">--deploy-mode client \ </span><br><span class="line">--driver-memory 512m \ </span><br><span class="line">--executor-memory 512m \ </span><br><span class="line">--num-executors 1 \ </span><br><span class="line">--total-executor-cores 2 \ </span><br><span class="line">$&#123;SPARK_HOME&#125;/examples/src/main/python/pi.py \ </span><br><span class="line">10</span><br></pre></td></tr></table></figure>
<p><img src="/../image/13.png"><br>采用cluster模式：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$&#123;SPARK_HOME&#125;/bin/spark-submit </span><br><span class="line">--master yarn \</span><br><span class="line">--deploy-mode cluster \</span><br><span class="line">--driver-memory 512m \</span><br><span class="line">--executor-memory 512m \</span><br><span class="line">--num-executors 1 \</span><br><span class="line">--total-executor-cores 2 \</span><br><span class="line">--conf&quot;spark.pyspark.driver.python=/export/server/anaconda3/envs/pyspark/bin/python&quot; \</span><br><span class="line">--conf&quot;spark.pyspark.python=/export/server/anaconda3/envs/pyspark/bin/python&quot; \</span><br><span class="line">$&#123;SPARK_HOME&#125;/examples/src/main/python/pi.py </span><br><span class="line">10</span><br></pre></td></tr></table></figure>
<p><img src="/../image/14.png"><br>注意：上面提到的路径根据个人环境修改。</p>
<h1 id="Spark-On-Yarn两种模式总结"><a href="#Spark-On-Yarn两种模式总结" class="headerlink" title="Spark On Yarn两种模式总结"></a>Spark On Yarn两种模式总结</h1><p>Client模式和Cluster模式最最本质的区别是：Driver程序运行在哪里<br>前者偏向于学习中测试使用，后者偏向于生产环境中</p>
<p>具体流程步骤如下：<br>（1）、Driver在任务提交的本地机器上运行，Driver启动后会和ResourceManager通讯申请启动ApplicationMaster ；<br>（2）、随后ResourceManager分配Container，在合适的NodeManager上启动ApplicationMaster，此时的 ApplicationMaster的功能相当于一个ExecutorLaucher，只负责向ResourceManager申请Executor内存；<br>（3）、ResourceManager接到ApplicationMaster的资源申请后会分配Container，然后ApplicationMaster在资源分 配指定的NodeManager上启动Executor进程；<br>（4）、Executor进程启动后会向Driver反向注册，Executor全部注册完成后Driver开始执行main函数；<br>（5）、之后执行到Action算子时，触发一个Job，并根据宽依赖开始划分Stage，每个Stage生成对应的TaskSet，之后 将Task分发到各个Executor上执行</p>
<h1 id="问题总结"><a href="#问题总结" class="headerlink" title="问题总结"></a>问题总结</h1><p>在测试StandAlone HA模式的时候，总会报错，查看日志发现是zookeeper没起来，还有在杀死node1上的master时发现进程一直连不上，最后才发现是node2的master没启动，所以说配置的时候一定要十分的细心。<br>在Spark On Yarn 配置中，在读取历史日志的时候，发现读取不了，上网查资料发现是安全模式打开了，然后把安全模式关闭就可以在18080端口看到历史服务了，也有Driver程序运行目录搞错了，没有切换到pyspark虚拟环境中等等，大多数错误就是不小心就踩坑了。</p>
]]></content>
  </entry>
</search>
